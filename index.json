
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["admin"],"categories":null,"content":"I am an Associate Professor in the Software Engineering Research Group (SERG) at Delft University of Technology (TU Delft) in the Netherlands. I am the head of the Computation Intelligence for Software Engineering Lab (CISELab) within SERG. My research interests include security testing, software testing, search-based software engineering, testing for AI, empirical software engineering. I serve and have served as a program committee member of various international conferences (e.g., ICSE, ESEC/FSE, ISSTA, GECCO, ICST) and as a reviewer for various international journals (e.g., TSE, TOSEM, TEVC, EMSE, STVR) in the fields of software engineering and evolutionary computation.\n","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am an Associate Professor in the Software Engineering Research Group (SERG) at Delft University of Technology (TU Delft) in the Netherlands. I am the head of the Computation Intelligence for Software Engineering Lab (CISELab) within SERG.","tags":null,"title":"Annibale Panichella","type":"authors"},{"authors":["C. Cao","S. Schneider","N. Ferreyraa","S. Verwer","A. Panichella","R. Scandariato"],"categories":null,"content":"Abstract:\nThe microservice architecture allows developers to divide the core functionality of their software system into multiple smaller services. However, this architectural style also makes it harder for them to debug and assess whether the system’s deployment conforms to its implementation. We present CATMA, an automated tool that detects non-conformances between the system’s deployment and implementation. It automatically visualizes and generates potential interpretations for the detected discrepancies. Our evaluation of CATMA shows promising results in terms of performance and providing useful insights. CATMA is available at https://cyber-analytics.nl/catma.github.io/, and a demonstration video is available at https://youtu.be/WKP1hG-TDKc.\n","date":1704130631,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704130631,"objectID":"f3d616d5157202619e2cb18dba088366","permalink":"https://example.com/publication/icse2024-tool/","publishdate":"2024-01-01T19:37:11+02:00","relpermalink":"/publication/icse2024-tool/","section":"publication","summary":"Abstract:\nThe microservice architecture allows developers to divide the core functionality of their software system into multiple smaller services. However, this architectural style also makes it harder for them to debug and assess whether the system’s deployment conforms to its implementation.","tags":["Microservices","Static Analysis","Dynamic Analysis","Software Testing","Empirical Software Engineering"],"title":"CATMA: Conformance Analysis Tool For Microservice Applications","type":"publication"},{"authors":["A. Sapozhnikov","M. Olsthoorn","A. Panichella","V.V. Kovalenko","A. Panichella","P. Derakhshanfar"],"categories":null,"content":"Abstract:\nWriting software tests is laborious and time-consuming. To address this, prior studies introduced various automated test-generation techniques. A well-explored research direction in this field is unit test generation, wherein artificial intelligence (AI) techniques create tests for a method/class under test. While many of these techniques have primarily found applications in a research context, existing tools (e.g., EvoSuite, Randoop, and AthenaTest) are not user-friendly and are tailored to a single technique. This paper introduces Test- Spark, a plugin for IntelliJ IDEA that enables users to generate unit tests with only a few clicks directly within their Integrated De- velopment Environment (IDE). Furthermore, TestSpark also allows users to easily modify and run each generated test and integrate them into the project workflow. TestSpark leverages the advances of search-based test generation tools, and it introduces a technique to generate unit tests using Large Language Models (LLMs) by creating a feedback cycle between the IDE and the LLM. Since TestSpark is an open-source (https://github.com/JetBrains-Research/TestSpark), extendable, and well-documented tool, it is possible to add new test generation methods into the plugin with the minimum effort. This paper also explains our future studies related to TestSpark and our preliminary results.\n","date":1704130631,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704130631,"objectID":"d758099c0c030314968870f51da67781","permalink":"https://example.com/publication/icse2024-tool2/","publishdate":"2024-01-01T19:37:11+02:00","relpermalink":"/publication/icse2024-tool2/","section":"publication","summary":"Abstract:\nWriting software tests is laborious and time-consuming. To address this, prior studies introduced various automated test-generation techniques. A well-explored research direction in this field is unit test generation, wherein artificial intelligence (AI) techniques create tests for a method/class under test.","tags":["Test Case Generation","Large Language Models","Evolutionary Testing","Intellij IDEA"],"title":"TestSpark: IntelliJ IDEA’s Ultimate Test Generation Companion","type":"publication"},{"authors":["June Sallou","Thomas Durieux","Annibale Panichella"],"categories":[],"content":"Abstract Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.\n","date":1702384190,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702384190,"objectID":"e9405a1121956cb1cb81038e32d2ecf5","permalink":"https://example.com/publication/icse-nier2024/","publishdate":"2023-12-12T14:29:50+02:00","relpermalink":"/publication/icse-nier2024/","section":"publication","summary":"Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.","tags":["Large Language Models","Artificial Intelligence","Replicability","Empirical Software Engineering","AI4SE"],"title":"Breaking the Silence: the Threats of Using LLMs in Software Engineering","type":"publication"},{"authors":["Imara van Dinten","Pouria Derakhshanfar","Annibale Panichella","Andy Zaidman"],"categories":null,"content":"","date":1701444774,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701444774,"objectID":"1fc3a9f28585bbeaf1ac67fb2bd336ae","permalink":"https://example.com/publication/jss2023/","publishdate":"2023-12-01T17:32:54+02:00","relpermalink":"/publication/jss2023/","section":"publication","summary":"Cyber-Physical Systems (CPSs) have gained traction in recent years. A major non-functional quality of CPS is performance since it affects both usability and security. This critical quality attribute depends on the specialized hardware, simulation engines, and environmental factors that characterize the system under analysis. While a large body of research exists on performance issues in general, studies focusing on performance-related issues for CPSs are scarce. The goal of this paper is to build a taxonomy of performance issues in CPSs. To this aim, we present two empirical studies aimed at categorizing common performance issues (Study I) and helping developers detect them (Study II). In the first study, we examined commit messages and code changes in the history of 14 GitHub-hosted open-source CPS projects to identify commits that report and fix self-admitted performance issues. We manually analyzed 2699 commits, labeled them, and grouped the reported performance issues into antipatterns. We detected instances of three previously reported Software Performance Antipatterns (SPAs) for CPSs. Importantly, we also identified new SPAs for CPSs not described earlier in the literature. Furthermore, most performance issues identified in this study fall into two new antipattern categories: Hard Coded Fine Tuning (399 of 646) and Magical Waiting Number (150 of 646). In the second study, we introduce static analysis techniques for automatically detecting these two new antipatterns; we implemented them in a tool called AP-Spotter. We analyzed 9 open-source CPS projects not utilized to build the SPAs taxonomy to benchmark AP-Spotter. Our results show that AP-Spotter achieves 62.04% precision in detecting the antipatterns","tags":["Software Performance Antipatterns","Cyber-Physical  Systems","Antipatterns Detection","Empirical Software Engineering","Static Analysis"],"title":"The Slow and The Furious? Performance Antipattern Detection in Cyber-Physical Systems","type":"publication"},{"authors":null,"categories":null,"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Organize your notebooks Place the notebooks that you would like to publish in a notebooks folder at the root of your website.\nImport the notebooks into your site pipx install academic academic import \u0026#39;notebooks/**.ipynb\u0026#39; content/post/ --verbose The notebooks will be published to the folder you specify above. In this case, they will be published to your content/post/ folder.\n","date":1699056000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699056000,"objectID":"94fa5e486d3bf3e0941e2ff6e7126c06","permalink":"https://example.com/post/blog-with-jupyter/","publishdate":"2023-11-04T00:00:00Z","relpermalink":"/post/blog-with-jupyter/","section":"post","summary":"Easily blog from Jupyter notebooks!","tags":null,"title":"Blog with Jupyter Notebooks!","type":"post"},{"authors":["Imara van Dinten","Andy Zaidman","Annibale Panichella"],"categories":null,"content":"Abstract Test case prioritization techniques have emerged as effective strategies to optimize this process and mitigate the regression testing costs. Commonly, black-box heuristics guide optimal test ordering, leveraging information retrieval (e.g., cosine distance) to measure the test case distance and sort them accordingly. However, a challenge arises when dealing with tests of varying granularity levels, as they may employ distinct vocabularies (e.g., name identifiers). In this paper, we propose to measure the distance between test cases based on the shortest path between their identifiers within the WordNet lexical database. This additional heuristic is combined with the traditional cosine distance to prioritize test cases in a multi-objective fashion. Our preliminary study conducted with two different Java projects shows that test cases prioritized with WordNet achieve larger fault detection capability (APFD) compared to the traditional cosine distance used in the literature.\n","date":1697613383,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697613383,"objectID":"58a9b8752fb8593fa12cf631bd6da75a","permalink":"https://example.com/publication/ssbse-nier2023/","publishdate":"2023-10-18T09:16:23+02:00","relpermalink":"/publication/ssbse-nier2023/","section":"publication","summary":"Abstract Test case prioritization techniques have emerged as effective strategies to optimize this process and mitigate the regression testing costs. Commonly, black-box heuristics guide optimal test ordering, leveraging information retrieval (e.","tags":["Test Case Prioritization","Search-based Software Testing","WordNet","Natural Language Processing","Multi-objective Optimization"],"title":"Multi-objective Black-Box Test Case Prioritization Based on Wordnet Distances","type":"publication"},{"authors":["Annibale Panichella","Giuseppe Di Domenico"],"categories":null,"content":"","date":1682413004,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682413004,"objectID":"277abed8952365168cec93e9aa6916e7","permalink":"https://example.com/publication/gecco2023a/","publishdate":"2023-04-25T10:56:44+02:00","relpermalink":"/publication/gecco2023a/","section":"publication","summary":"Spatial mode division de-multiplexing of optical signals has many real-world applications, such as quantum computing and both classical and quantum optical communication. In this context, it is crucial to develop devices able to efficiently sort optical signals according to the optical mode they belong to and route them on different paths. Depending on the mode selected, this problem can be very hard to tackle. Recently, researchers have proposed using multi-objective evolutionary algorithms (MOEAs) ---and NSGA-II in particular--- combined with Linkage Learning (LL) to automate the process of design mode sorter. However, given the very large-search scale of the problem, the existing evolutionary-based solutions have a very slow convergence rate. In this paper, we proposed a novel approach for mode sorter design that combines (1) stochastic linkage learning, (2) the adaptive geometry estimation-based MOEA (AGE-MOEA-II), and (3) an adaptive mutation operator. Our experiments with two- and three-objectives (beams) show that our approach is faster (better convergence rate) and produces better mode sorters (closer to the ideal solutions) than the state-of-the-art approach. A direct comparison with the vanilla NSGA-II and AGE-MOEA-II also further confirms the importance of adopting LL in this domain.","tags":["Multi-objective Optimization","Mode sorter","Integrated Photonics","Evolutionary Computation","Hierarchical Clustering"],"title":"A Fast Multi-objective Evolutionary Approach for Designing Large-Scale Optical Mode Sorter","type":"publication"},{"authors":["Leonhard Applis","Ruben Marang","Annibale Panichella"],"categories":null,"content":"","date":1682413004,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682413004,"objectID":"366615352dccfaa23a88d384b4559ac5","permalink":"https://example.com/publication/gecco2023b/","publishdate":"2023-04-25T10:56:44+02:00","relpermalink":"/publication/gecco2023b/","section":"publication","summary":"More machine learning (ML) models are introduced to the field of Software Engineering (SE) and reached a stage of maturity to be considered for real-world use;But the real world is complex, and testing these models lacks often in explainability, feasability and computational capacities. Existing research introduced metamorphic testing to gain additional insights and certainty about the model, by applying semantic-preserving changes to input-data while observing model-output. As this is currently done at random places, it can lead to potentially unrealistic datapoints and high computational costs. With this work, we introduce genetic search as an additional aid for metamorphic testing in SE ML. Utilizing the delta in output as a fitness function, the evolutionary intelligence optimizes the transformations to produce higher deltas with less changes. We perform a case study minimizing F1-Score and MRR for Code2Vec on a representative sample from java-small with both genetic and random search. Our results show that within the same amount of time, genetic search was able to achieve a decrease of 10% in F1 while random search produced 3% drop.","tags":["Machine Learning","Metamorphic Testing","Genetic Algorithm"],"title":"Searching for Quality: Genetic Algorithms and Metamorphic Testing for Software Engineering ML","type":"publication"},{"authors":["M.C. van Meerten"," Burcu Kulahcioglu Ozkan","Annibale Panichella"],"categories":[],"content":"","date":1672604871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672604871,"objectID":"440b8ec1887c67d16194b70a6315a9c8","permalink":"https://example.com/publication/icse-seip2023/","publishdate":"2023-01-01T22:27:51+02:00","relpermalink":"/publication/icse-seip2023/","section":"publication","summary":"","tags":["Ripple","Blockchain","Distributed Systems","Evolutionary approaches","Software testing","Concurrency"],"title":"Evolutionary Approach for Concurrency Testing of Ripple Blockchain Consensus Algorithm","type":"publication"},{"authors":["Leonhard Applis","Annibale Panichella"],"categories":null,"content":"","date":1672589317,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672589317,"objectID":"e72704a870140a8031773039efb1a598","permalink":"https://example.com/publication/msrdata2023/","publishdate":"2023-01-01T17:08:37+01:00","relpermalink":"/publication/msrdata2023/","section":"publication","summary":"We present HasBugs, a manually collected Dataset of 25 Haskell Bugs from 6 Open Source Repositories. We provide buggy, tested and fixed versions as well as reproduction packages and a summary of the bug and its context. For technical users,the dataset is meant to either help researchers adopt techniques from other Languages for Haskell or to provide a human-verified gold standard for tool-evaluation. We also see applicability for qualitative research, e.g. by analysis of bug-lifecycles and comparison to other languages. We provide a companion website for easy access and overview under https://ciselab.github.io/HasBugs/","tags":["Log Analysis","Dataset"],"title":"HasBugs - Handpicked Haskell Bugs","type":"publication"},{"authors":["Lisette Veldkamp","Mitchell Olsthoorn","Annibale Panichella"],"categories":null,"content":"","date":1672588600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672588600,"objectID":"b2dda9593cb0795db0578f308cd94f05","permalink":"https://example.com/publication/sbft2023-rpc/","publishdate":"2023-01-01T17:56:40+02:00","relpermalink":"/publication/sbft2023-rpc/","section":"publication","summary":"Web Application Programming Interfaces (APIs) allow systems to be addressed programmatically and form the backbone of the internet. RESTful and RPC APIs are among the most common API architectures used. In the last decades, researchers have proposed various techniques for automated testing of RESTful APIs, however, to the best of the authors' knowledge there exists no work on testing JSON-RPC (one of the two data formats supported by RPC) APIs. To address this limitation, we propose a grammar-based evolutionary fuzzing approach for testing JSON-RPC APIs that uses a novel black-box heuristics. Specifically, we use a diversity-based fitness function based on hierarchical clustering to quantify the differences in API method responses. Our hypothesis is that responses that are unlike previously seen ones are an indication that new uncovered code paths are reached. We evaluate our approach on the XRP ledger, a large-scale industrial blockchain system that uses JSON-RPC APIs. Our results show that the proposed approach performs significantly better than the baseline (grammar-based fuzzer) and covers an additional 240 branches.","tags":["",""],"title":"Grammar-Based Evolutionary Fuzzing for JSON-RPC APIs","type":"publication"},{"authors":["Antony Bartlett","Cynthia C. S. Liem","Annibale Panichella"],"categories":null,"content":"","date":1672588600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672588600,"objectID":"b1585da1d66de3e08e50e67287612d36","permalink":"https://example.com/publication/sbft2023-pixelmoo/","publishdate":"2023-01-01T17:56:40+02:00","relpermalink":"/publication/sbft2023-pixelmoo/","section":"publication","summary":"Deep learning (DL) models are known to be highly accurate, yet vulnerable to adversarial examples. While earlier research focused on generating adversarial examples using whitebox strategies, later research focused on black-box strategies, as models often are not accessible to external attackers. Prior studies showed that black-box approaches based on approximate gradient descent algorithms combined with meta-heuristic search (i.e., the BMI-FGSM algorithm) outperform previously proposed white- and black-box strategies. In this paper, we propose a novel black-box approach purely based on differential evolution (DE), i.e., without using any gradient approximation method. In particular, we propose two variants of a customized DE with customized variation operators: (1) a single-objective (Pixel-SOO) variant generating attacks that fool DL models, and (2) a multi-objective variant (Pixel-MOO) that also minimizes the number of changes in generated attacks. Our preliminary study on five canonical image classification models shows that Pixel-SOO and Pixel-MOO are more effective than the state-of-the-art BMI-FGSM in generating adversarial attacks. Furthermore, Pixel-SOO is faster than Pixel-MOO, while the latter produces subtler attacks than its single-objective variant.","tags":["",""],"title":"On the Strengths of Pure Evolutionary Algorithms in Generating Adversarial Examples","type":"publication"},{"authors":["Xavier Devroey","Alessio Gambi","Juan Pablo Galeotti","René Just","Fitsum Kifetew","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1670836282,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670836282,"objectID":"baf9cc9e83b2bda3ada1b40dd0785cf3","permalink":"https://example.com/publication/stvr2022/","publishdate":"2022-12-12T11:11:22+02:00","relpermalink":"/publication/stvr2022/","section":"publication","summary":"","tags":["Mutation Testing"],"title":"JUGE: An Infrastructure for Benchmarking Java Unit Test Generators","type":"publication"},{"authors":["Fiorella Zampetti","Damian Tamburri","Sebastiano Panichella","Annibale Panichella","Gerardo Canfora"," Massimiliano di Penta"],"categories":null,"content":"","date":1668158505,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668158505,"objectID":"50247d9529f61e7cad150fba9fc6aa81","permalink":"https://example.com/publication/acm-tosem2022b/","publishdate":"2022-11-11T11:21:45+02:00","relpermalink":"/publication/acm-tosem2022b/","section":"publication","summary":"","tags":["Cyber-Physical Systems","Continuous Integration and Delivery","Empirical Software Engineering"],"title":"Continuous Integration and Delivery practices for Cyber- Physical systems: An interview-based study","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Annibale Panichella","Andy Zaidman","Arie van Deursen"],"categories":null,"content":"Abstract: Search-based approaches have been used in the literature to automate the process of creating unit test cases. However, related work has shown that generated tests with high code coverage could be ineffective, i.e., they may not detect all faults or kill all injected mutants. In this paper, we propose CLING, an integration-level test case generation approach that exploits how a pair of classes, the caller and the callee, interact with each other through method calls. In particular, CLING generates integration-level test cases that maximize the Coupled Branches Criterion (CBC). Coupled branches are pairs of branches containing a branch of the caller and a branch of the callee such that an integration test that exercises the former also exercises the latter. CBC is a novel integration-level coverage criterion, measuring the degree to which a test suite exercises the interactions between a caller and its callee classes. We implemented CLING and evaluated the approach on 140 pairs of classes from five different open-source Java projects. Our results show that (1) CLING generates test suites with high CBC coverage, thanks to the definition of the test suite generation as a many-objectives problem where each couple of branches is an independent objective; (2) such generated suites trigger different class interactions and can kill on average 7.7% (with a maximum of 50%) of mutants that are not detected by tests generated randomly or at the unit level; (3) CLING can detect integration faults coming from wrong assumptions about the usage of the callee class (25 for our subject systems) that remain undetected when using automatically generated random and unit-level test suites.\n","date":1663054154,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663054154,"objectID":"b044fb3791b7b73acd99a83a652bdad1","permalink":"https://example.com/publication/ieee-tse2022/","publishdate":"2022-09-13T09:29:14+02:00","relpermalink":"/publication/ieee-tse2022/","section":"publication","summary":"Abstract: Search-based approaches have been used in the literature to automate the process of creating unit test cases. However, related work has shown that generated tests with high code coverage could be ineffective, i.","tags":["Test Case Generation","Fuzzing","Search-based Software Engineering","Cling","Software Testing","Many-objective Optimization"],"title":"Generating Class-Level Integration Tests Using Call Site Information","type":"publication"},{"authors":["Dimitri Stallenberg","Mitchell Olsthoorn","Annibale Panichella"],"categories":null,"content":"Abstract Search-based test case generation approaches make use of static type information to determine which data types should be used for the creation of new test cases. Dynamically typed languages like JavaScript, however, do not have this type information. In this paper, we propose an unsupervised probabilistic type inference approach to infer data types within the test case generation process. We evaluated the proposed approach on a benchmark of 98~units under test (i.e., exported classes and functions) compared to random type sampling w.r.t. branch coverage. Our results show that our type inference approach achieves a statistically significant increase in 56% of the test files with up to 71% of branch coverage compared to the baseline.\n","date":1660806983,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660806983,"objectID":"5160595246ad82c17628843e189d3459","permalink":"https://example.com/publication/ssbse2022/","publishdate":"2022-08-18T09:16:23+02:00","relpermalink":"/publication/ssbse2022/","section":"publication","summary":"Abstract Search-based test case generation approaches make use of static type information to determine which data types should be used for the creation of new test cases. Dynamically typed languages like JavaScript, however, do not have this type information.","tags":["Test Case Generation","Many-objective Optimization","JavaScript","Software Testing","Search-based Software Engineering"],"title":"Guess What: Test Case Generation for Javascript with Unsupervised Probabilistic Type Inference","type":"publication"},{"authors":["Annibale Panichella","Sebastiano Panichella","Gordon Fraser","Anand Ashok Sawant","Vincent Hellendoorn"],"categories":[],"content":"","date":1658396054,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658396054,"objectID":"d89ea7d71b593897d1775a1537572538","permalink":"https://example.com/publication/emse2022/","publishdate":"2022-07-21T11:34:14+02:00","relpermalink":"/publication/emse2022/","section":"publication","summary":"Test smells aim to capture design issues in test code that reduces its maintainability. These have been extensively studied and generally found quite prevalent in both human-written and automatically generated test-cases. However, most evidence of prevalence is based on specific static detection rules. Although those are based on the original, conceptual definitions of the various test smells, recent empirical studies indicate that developers perceive warnings raised by detection tools as overly strict and non-representative of the maintainability and quality of test suites. This leads us to re-assess test smell detection tools' detection accuracy and investigate the prevalence and detectability of test smells more broadly. Specifically, we construct a hand-annotated dataset spanning hundreds of test suites both written by developers and generated by two test generation tools (EvoSuite and JTExpert) and performed a multi-stage, cross-validated manual analysis to identify the presence of six types of test smells in these. We then use this manual labeling to benchmark the performance and external validity of two test smell detection tools -- one widely used in prior work and one recently introduced with the express goal to match developer perceptions of test smells. Our results primarily show that the current vocabulary of test smells is highly mismatched to real concerns: multiple smells were ubiquitous on developer-written tests but virtually never correlated with semantic or maintainability flaws; machine-generated tests actually often scored better, but in reality, suffered from a host of problems not well-captured by current test smells. Current test smell detection strategies poorly characterized the issues in these automatically generated test suites; in particular, the older tool's detection strategies misclassified over 70% of test smells, both missing real instances (false negatives) and marking many smell-free tests as smelly (false positives). We identify common patterns in these tests that can be used to improve the tools, refine and update the definition of certain test smells, and highlight as of yet uncharacterized issues. Our findings suggest the need for (i) more appropriate metrics to match development practice, (ii) more accurate detection strategies to be evaluated primarily in industrial contexts.","tags":["Test Case Generation","Unit Testing","Test Smells","Replication Study"],"title":"Test Smells 20 Years Later: Detectability, Validity, and Reliability","type":"publication"},{"authors":["Mitchell Olsthoorn","Arie van Deursen","Annibale Panichella"],"categories":[],"content":"","date":1654965828,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654965828,"objectID":"b46b5a48499bf8138c3dc849da11a5f3","permalink":"https://example.com/publication/icsme2022/","publishdate":"2022-06-11T18:43:48+02:00","relpermalink":"/publication/icsme2022/","section":"publication","summary":"Transaction-reverting statements are key constructs within Solidity that are extensively used for authority and validity checks. Current state-of-the-art search-based testing and fuzzing approaches do not explicitly handle these statements and therefore can not effectively detect security vulnerabilities. In this paper, we argue that it is critical to directly handle and test these statements to assess that they correctly protect the contracts against invalid requests. To this aim, we propose a new approach that improves the search guidance for these transaction-reverting statements based on interprocedural control dependency analysis, in addition to the traditional coverage criteria. We assess the benefits of our approach by performing an empirical study on 100 smart contracts w.r.t. transaction-reverting statement coverage and vulnerability detection capability. Our results show that the proposed approach can improve the performance of DynaMOSA, the state-of-the-art algorithm for test case generation. On average, we improve transaction-reverting statement coverage by 14 % (up to 35 %), line coverage by 8 % (up to 32 %), and vulnerability-detection capability by 17 % (up to 50 %).","tags":["Test Case Generation","Fuzzing","Smart Contracts","Search-based Software Engineering"],"title":"Guiding Automated Test Case Generation for Transaction-Reverting Statements in Smart Contracts","type":"publication"},{"authors":["Christian Birchler","Sajad Khatiri","Pouria Derakhshanfar","Sebastiano Panichella","Annibale Panichella"],"categories":null,"content":"","date":1649064105,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649064105,"objectID":"026c9cebe722dee45f37135747b2c5db","permalink":"https://example.com/publication/acm-tosem2022/","publishdate":"2022-04-04T11:21:45+02:00","relpermalink":"/publication/acm-tosem2022/","section":"publication","summary":"","tags":["Self-driving Cars","Regression Testing","Multi-objective Optimization","Search-based Software Engineering"],"title":"Single and Multi-objective Test Cases Prioritization for Self-driving Cars in Virtual Environments","type":"publication"},{"authors":["Annibale Panichella"],"categories":null,"content":"","date":1648371404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648371404,"objectID":"1d6fbf4a9e41579eef76a49fb42150a4","permalink":"https://example.com/publication/gecco2022/","publishdate":"2022-03-27T10:56:44+02:00","relpermalink":"/publication/gecco2022/","section":"publication","summary":"A key idea in many-objective optimization is to approximate the optimal Pareto front using a set of representative non-dominated solutions. The produced solution set should be close to the optimal front (convergence) and well-diversified (diversity). Recent studies have shown that measuring both convergence and diversity depends on the shape (or curvature) of the Pareto front. In recent years, researchers have proposed evolutionary algorithms that model the shape of the non-dominated front to define environmental selection strategies that adapt to the underlying geometry. This paper proposes a novel method for non-dominated front modeling using the Newton-Raphson iterative method for roots finding. Second, we compute the distance (diversity) between each pair of non-dominated solutions using geodesics, which are generalizations of the distance on Riemann manifolds (curved topological spaces). Thereafter, we have introduced an evolutionary algorithm within the Adaptive Geometry Estimation based MOEA (AGE-MOEA) framework, which we called AGE-MOEA-II. Computational experiments with 17 problems from the WFG and SMOP benchmarks show that AGE-MOEA-II outperforms its predecessor AGE-MOEA as well as other state-of-the-art many-objective algorithms, i.e., NSGA-III, MOEA/D, VaEA, and LMEA.","tags":["Many-objective Optimization","Numerical Problems","Evolutionary Computation"],"title":"An Improved Pareto Front Modeling Algorithm for Large-scale Many-Objective Optimization","type":"publication"},{"authors":null,"categories":null,"content":"","date":1647595035,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647595035,"objectID":"7fbb2665208c57de319ed3397f35bfa8","permalink":"https://example.com/talk/do-tests-generated-by-ai-help-developers-open-challenges-applications-and-opportunities/","publishdate":"2022-03-18T11:17:15+02:00","relpermalink":"/talk/do-tests-generated-by-ai-help-developers-open-challenges-applications-and-opportunities/","section":"event","summary":"","tags":[],"title":"Do Tests Generated by AI Help Developers? Open Challenges, Applications, and Opportunities","type":"event"},{"authors":["Mitchell Olsthoorn ","Dimitri Stallenberg","Arie van Deursen","Annibale Panichella"],"categories":[],"content":"","date":1642508990,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642508990,"objectID":"040fac553c24c3e9d3d6bfe79975828c","permalink":"https://example.com/publication/icse-demo2022/","publishdate":"2022-01-18T14:29:50+02:00","relpermalink":"/publication/icse-demo2022/","section":"publication","summary":"Ethereum is the largest and most prominent smart contract platform. One key property of Ethereum is that once a contract is deployed, it can not be updated anymore. This increases the importance of thoroughly testing the behavior and constraints of the smart contract before deployment. Existing approaches in related work either do not scale or are only focused on finding crashing inputs. In this tool demo, we introduce SynTest-Solidity, an automated test case generation and fuzzing framework for Solidity. SynTest-Solidity implements various metaheuristic search algorithms, including random search (traditional fuzzing) and genetic algorithms (i.e., NSGA-II, MOSA, and DynaMOSA). Finally, we performed a preliminary empirical study to assess the effectiveness of SynTest-Solidity in testing Solidity smart contracts.","tags":["Fuzzing","Test Case Generation","Smart Contracts","Testing"],"title":"SynTest-Solidity: Automated Test Case Generation and Fuzzing for Smart Contracts","type":"publication"},{"authors":["Giuseppe Di Domenico","Dror Weisman","Annibale Panichella","Dolev Roitman","Ady Arie"],"categories":[],"content":"","date":1641027451,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639990651,"objectID":"3a221bb6ff048adff98593cc06de714d","permalink":"https://example.com/publication/acsphotonics2022/","publishdate":"2022-01-01T09:57:31+01:00","relpermalink":"/publication/acsphotonics2022/","section":"publication","summary":"","tags":["Clustering","Machine Learning","Evolutionary Algorithms","On-chip Sorting","Hermite-Gaussian beams"],"title":"Large scale inverse design of planar on-chip mode sorter","type":"publication"},{"authors":["Matthías Páll Gissurarson","Leonhard Applis","Annibale Panichella","Arie van Deursen","David Sands"],"categories":[],"content":"","date":1641025959,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639989159,"objectID":"7cdfe2d93c7fb175db17d96d1e8d6b07","permalink":"https://example.com/publication/icse2022/","publishdate":"2022-01-01T09:32:39+01:00","relpermalink":"/publication/icse2022/","section":"publication","summary":"Automatic program repair (APR) regularly faces the challenge of overfitting patches that pass the test suite, but do not actually address the problems when evaluated manually. Currently, overfit detection requires manual inspection or an oracle making quality control of APR an expensive task. With this work, we want to introduce properties in addition to unit tests for APR to address the problem of overfitting. To that end, we design and implement PropR, a program repair tool for Haskell that leverages both property-based testing (via QuickCheck) and the rich type system and synthesis offered by the Haskell compiler. We compare the repair-ratio, time-to-first-patch and overfitting-ratio when using unit tests, property-based tests, and their combination. Our results show that properties lead to quicker results and have a lower overfit ratio than unit tests. The created overfit patches provide valuable insight into the underlying problems of the program to repair (e.g., in terms of fault localization or test quality). We consider this step towards fitter, or at least insightful, patches a critical contribution to bring APR into developer workflows.","tags":["Program Repair","Property","Genetic Programming","Haskell"],"title":"PropR: Property-Based Automatic Program Repair","type":"publication"},{"authors":["Leonhard Applis","Annibale Panichella","Arie van Deursen"],"categories":[],"content":"","date":1628368071,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628368071,"objectID":"4441a5d69b97f3bb7e96e293d3a20bc4","permalink":"https://example.com/publication/ase2021-nier/","publishdate":"2021-08-07T22:27:51+02:00","relpermalink":"/publication/ase2021-nier/","section":"publication","summary":"Metamorphic testing is a well-established testing technique that has been successfully applied in various domains, including testing deep learning models to assess their robustness against data noise or malicious input. Currently, metamorphic testing approaches for machine learning (ML) models focused on image processing and object recognition tasks. Hence, these approaches cannot be applied to ML targeting program analysis tasks. In this paper, we extend metamorphic testing approaches for ML models targeting software programs. We present Lampion, a novel testing framework that applies (semantics preserving) metamorphic transformations on the test datasets. Lampion produces new code snippets equivalent to the original test set but different in their identifiers or syntactic structure. We evaluate Lampion against CodeBERT, a state-of-the-art ML model for Code-To-Text tasks that creates Javadoc summaries for given Java methods. Our results show that simple transformations significantly impact the target model behavior, providing additional information on the models reasoning apart from the classic performance metric.","tags":["Metamorphic testing","Machine Learning","Deep Learning","AI for SE"],"title":"\tAssessing Robustness of ML-Based Program Analysis Tools using Metamorphic Program Transformations","type":"publication"},{"authors":["Dimitri Stallenberg","Mitchell Olsthoorn","Annibale Panichella"],"categories":[],"content":"","date":1625689671,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625689671,"objectID":"fd843d1bc3180fa73faab6df3e297bb4","permalink":"https://example.com/publication/ase2021/","publishdate":"2021-07-07T22:27:51+02:00","relpermalink":"/publication/ase2021/","section":"publication","summary":"Automated test case generation tools have been successfully pro- posed to reduce the amount of human and infrastructure resources required to write and run test cases. However, recent studies demonstrate that the readability of generated tests is very limited due to (i) uninformative identifiers and (ii) lack of proper documentation. Prior studies proposed techniques to improve test readability by either generating natural language summaries or meaningful methods names. While these approaches are shown to improve test readability, they are also affected by two limitations: (1) generated summaries are often perceived as too verbose and redundant by developers, and (2) readable tests require both proper method names but also meaningful identifiers (within-method readability). In this work, we combine template based methods and Deep Learning (DL) approaches to automatically generate test case scenarios (elicited from natural language patterns of test case statements) as well as to train DL models on path-based representations of source code to generate meaningful identifier names. Our ap- proach, called DeepTC-Enhancer , recommends documentation and identifier names with the ultimate goal of enhancing readability of automatically generated test cases. An empirical evaluation with 36 external and internal developers shows that (1) DeepTC-Enhancer outperforms significantly the baseline approach for generating summaries and performs equally with the baseline approach for test case renaming, (2) the transformation proposed by DeepTC-Enhancer result in a significant increase in readability of automatically generated test cases, and (3) there is a significant difference in the feature preferences between external and internal developers.","tags":["Test Case Generation","Clustering","Machine Learning","EvoMaster","RESTful API"],"title":"Improving Test Case Generation for REST APIs Through Hierarchical Clustering","type":"publication"},{"authors":["Mitchell Olsthoorn","Pouria Derakhshanfar","Annibale Panichella"],"categories":null,"content":"Abstract State-of-the-art search-based approaches for test case generation work at test case level, where tests are represented as sequences of statements. These approaches make use of genetic operators (i.e., mutation and crossover) that create test variants by adding, altering, and removing statements from existing tests. While this encoding schema has been shown to be very effective for many-objective test case generation, the standard crossover operator (single-point) only alters the structure of the test cases but not the input data. In this paper, we argue that changing both the test case structure and the input data is necessary to increase the genetic variation and improve the search process. Hence, we propose a hybrid multi-level crossover (HMX) operator that combines the traditional test-level crossover with data-level recombination. The former evolves and alters the test case structures, while the latter evolves the input data using numeric and string-based recombinational operators. We evaluate our new crossover operator by performing an empirical study on more than 100 classes selected from open-source Java libraries for numerical operations and string manipulation. We compare HMX with the single-point crossover that is used in EvoSuite w.r.t structural coverage and fault detection capability. Our results show that HMX achieves a statistically significant increase in 30% of the classes up to 19% in structural coverage compared to the single-point crossover. Moreover, the fault detection capability improved up to 12% measured using strong mutation score.\n","date":1624950983,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624950983,"objectID":"83ccee878cd62cc649ec029f7211f77c","permalink":"https://example.com/publication/ssbse2021b/","publishdate":"2021-06-29T09:16:23+02:00","relpermalink":"/publication/ssbse2021b/","section":"publication","summary":"Abstract State-of-the-art search-based approaches for test case generation work at test case level, where tests are represented as sequences of statements. These approaches make use of genetic operators (i.e., mutation and crossover) that create test variants by adding, altering, and removing statements from existing tests.","tags":["Test Case Generation","Many-objective Optimization","EvoSuite"],"title":"Hybrid Multi-level Crossover for Unit Test Case Generation","type":"publication"},{"authors":["Mitchell Olsthoorn","Annibale Panichella"],"categories":null,"content":"Abstract Test case selection (TCS) aims to select a subset of the test suite to run for regression testing. The selection is typically based on past coverage and execution cost data. Researchers have successfully used multi-objective evolutionary algorithms (MOEAs), such as NSGA-II and its variants, to solve the problem. These MOEAs use traditional crossovers to create new candidate solutions during the search. Recent studies in evolutionary computation showed that more effective recombinations can be made by using linkage learning. Inspired by these recent advances in this field, we propose a new variant of NSGA-II, called L2-NSGA, that uses linkage learning to optimize test case selection. In particular, we use an unsupervised clustering algorithm to infer promising patterns among the solutions (sub-test suites). Then, these patterns are used in the next iterations of L2-NSGA to create solutions that contain/preserve these inferred patterns. Our results show that our customizations make NSGA-II more effective for test case selection. Furthermore, the test suite sub-sets generated by L2-NSGA are less expensive and more effective (detect more faults) than those generated by MOEAs used in the literature for regression testing.\n","date":1624950983,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624950983,"objectID":"3fdde29bf1a1b355ac09cd386e9fd315","permalink":"https://example.com/publication/ssbse2021a/","publishdate":"2021-06-29T09:16:23+02:00","relpermalink":"/publication/ssbse2021a/","section":"publication","summary":"Abstract Test case selection (TCS) aims to select a subset of the test suite to run for regression testing. The selection is typically based on past coverage and execution cost data.","tags":["Regression Testing","Machine Learning","Multi-objective Optimization","Search-based Software Engineering","Test Case Selection"],"title":"Multi-objective Test Case Selection Through Linkage Learning-driven Crossover","type":"publication"},{"authors":null,"categories":null,"content":"","date":1622107035,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622107035,"objectID":"e7ab7d9ef76a2234d0632539b21b89d0","permalink":"https://example.com/talk/what-are-we-really-testing-in-mutation-testing-for-machine-learning-a-critical-reflection/","publishdate":"2021-05-27T11:17:15+02:00","relpermalink":"/talk/what-are-we-really-testing-in-mutation-testing-for-machine-learning-a-critical-reflection/","section":"event","summary":"","tags":["Mutation Testing","Deep Learning"],"title":"What Are We Really Testing in Mutation Testing for Machine Learning? A Critical Reflection","type":"event"},{"authors":["Salma Messaoudi","Donghwan Shin","Annibale Panichella","Domenico Bianculli","Lionel Briand"],"categories":null,"content":"","date":1618815836,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618815836,"objectID":"9be3039c9c1cd9613478915f04c0242a","permalink":"https://example.com/publication/issta2021/","publishdate":"2021-04-19T09:03:56+02:00","relpermalink":"/publication/issta2021/","section":"publication","summary":"Regression testing is arguably one of the most important activities in software testing. However, its cost-effectiveness and usefulness can be largely impaired by complex system test cases that are poorly designed (e.g., test cases containing  multiple test scenarios combined into a single test case) and that require a large amount of time and resources to run.  One way to mitigate this issue is decomposing such system test cases into smaller, separate test cases---each of them with only one test scenario and with its corresponding assertions---so that the execution time of the decomposed test cases is lower than the original test cases, while the test effectiveness of the original test cases is preserved. This decomposition can be achieved with program slicing techniques, since test cases are software programs too. However, existing static and dynamic slicing techniques exhibit limitations when (1) the test cases use external resources, (2) code instrumentation is not a viable option, and (3) test execution is expensive.  In this paper, we propose a novel approach, called DS3 (Decomposing System teSt caSe), which automatically decomposes a complex system test case into separate test case slices. The idea is to use test case execution logs, obtained from past regression testing sessions, to identify ``hidden'' dependencies in the slices generated by static slicing. Since logs include run-time information about the system under test, we can use them to extract access and usage of global resources and refine the slices generated by static slicing.  We evaluated DS3 in terms of slicing effectiveness and compared it with a vanilla static slicing tool. We also compared the slices obtained by DS3 with the corresponding original system test cases, in terms of test efficiency and effectiveness. The evaluation results on one proprietary system and one open-source system show that DS3 is able to accurately identify the dependencies related to the usage of global resources, which vanilla static slicing misses. Moreover, the generated test case slices are, on average, 3.56 times faster than original system test cases and they exhibit no significant loss in terms of fault detection effectiveness.","tags":["Log Analysis","Test case slicing","Regression Testing","Software Testing","Test Smell"],"title":"Log-based Slicing for System-level Test Cases","type":"publication"},{"authors":["S. Vogl","S. Schweikl","G. Fraser","A. Arcuri","J. Campos","A. Panichella"],"categories":null,"content":"","date":1617292600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617292600,"objectID":"f0bef738ea1b1c30edbaa59702751c92","permalink":"https://example.com/publication/sbst2021/","publishdate":"2021-04-01T17:56:40+02:00","relpermalink":"/publication/sbst2021/","section":"publication","summary":"EvoSuite is a search-based tool that automatically generates executable unit tests for Java code (JUnit tests). This paper summarises the results and experiences of EvoSuite participation at the ninth unit testing competition at SBST 2021, where EvoSuite achieved the highest overall score.","tags":["Test Case Generation","EvoSuite"],"title":"EvoSuite at the SBST 2021 Tool Competition","type":"publication"},{"authors":["Annibale Panichella","Cynthia C. S. Liem"],"categories":[],"content":"","date":1610972990,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579350590,"objectID":"9a7acffa695edc5e6117d9c066e0e56e","permalink":"https://example.com/publication/icse-nier2020/","publishdate":"2021-01-18T14:29:50+02:00","relpermalink":"/publication/icse-nier2020/","section":"publication","summary":"Mutation testing is a well-established technique for assessing a test suite's effectiveness by injecting artificial faults into production code. In recent years, mutation testing has been extended to machine learning (ML) systems and deep learning (DL) in particular. Researchers have proposed approaches, tools, and statistically sound heuristics to determine whether mutants in DL systems are killed or not. However, as we will argue in this work, questions can be raised to what extent currently used mutation testing techniques in DL are actually in line with the classical interpretation of mutation testing. As we will discuss, in current approaches, the distinction between production and test code is blurry, the realism of mutation operators can be challenged, and generally, the degree to which the hypotheses underlying classical mutation testing (competent programmer hypothesis and coupling effect hypothesis) are followed lacks focus and explicit mappings. In this paper, we observe that ML model development follows a test-driven development (TDD) process, where data points (test data) with labels (implicit assertions) correspond to test cases in traditional software. Based on this perspective, we critically revisit existing mutation operators for ML, the mutation testing paradigm for ML, and its fundamental hypotheses. Based on our observations, we propose several action points for better alignment of mutation testing techniques for ML with paradigms and vocabularies of classical mutation testing.","tags":["Fuzzing","Mutation Testing","Machine Learning","Software Testing","Deep Learning"],"title":"What Are We Really Testing in Mutation Testing for Machine Learning? A Critical Reflection","type":"publication"},{"authors":["Casper Schroder","A. van der Feltz","Annibale Panichella","Mauricio Aniche"],"categories":[],"content":"","date":1609532871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577910471,"objectID":"1e5fce5155268b75032e69cc895eca7e","permalink":"https://example.com/publication/icse-seip2020/","publishdate":"2021-01-01T22:27:51+02:00","relpermalink":"/publication/icse-seip2020/","section":"publication","summary":"","tags":["Refactoring","Search-based Software Engineering","Software Quality"],"title":"Search-Based Software Re-Modularization: A Case Study at Adyen","type":"publication"},{"authors":["B. Yildiz","H. Hung","J. H. Krijthe","C. C. S. Liem","M. Loog","G. Migut","F. Oliehoek","A. Panichella","P. Paweczak","S. Picek","M. de Weerdt","J. van Gemert"],"categories":null,"content":"","date":1609515174,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609515174,"objectID":"fd36b0cde9bc5a5da3c336c68ccb0fac","permalink":"https://example.com/publication/rrpr2021/","publishdate":"2021-01-01T17:32:54+02:00","relpermalink":"/publication/rrpr2021/","section":"publication","summary":"We present ReproducedPaper.org: an open online repository for teaching and structuring machine learning reproducibility. We evaluate doing a reproduction project among students and the added value of an online reproduction repository among AI researchers. We use  anonymous self-assessment surveys and obtained 144 responses. Results suggest that students who do a reproduction project place more value on scientific reproductions and become more critical thinkers.  Students and AI researchers agree that our online reproduction repository is valuable.","tags":["Machine Learning","Reproducibility"],"title":"ReproducedPaper.org: Openly teaching and structuring machine learning reproducibility","type":"publication"},{"authors":["Annibale Panichella","吳恩達"],"categories":["Demo","教程"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It’s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy’s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you’ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://example.com/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Hugo Blox Builder, the website builder for Hugo","type":"post"},{"authors":["Qianqian Zhou","Andy Zaidman","Annibale Panichella"],"categories":null,"content":"","date":1606836774,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606836774,"objectID":"d71fd0a87b526da4df57f23dd76471cc","permalink":"https://example.com/publication/jss2020/","publishdate":"2020-12-01T17:32:54+02:00","relpermalink":"/publication/jss2020/","section":"publication","summary":"Mutation testing is well-known for its efficacy in assessing test quality, and starting to be applied in the industry. However, what should a developer do when confronted with a low mutation score? Should the test suite be plainly reinforced to increase the mutation score, or should the production code be improved as well, to make the creation of better tests possible? In this paper, we aim to provide a new perspective to developers that enables them to understand and reason about the mutation score in the light of testability and observability. First, we investigate whether testability and observability metrics are correlated with the mutation score on six open-source Java projects. We observe a correlation between observability metrics and the mutation score, e.g., test directness, which measures the extent to which the production code is tested directly, seems to be an essential factor. Based on our insights from the correlation study, we propose a number of ''mutation score anti-patterns''', enabling software engineers to refactor their existing code or add tests to improve the mutation score. In doing so, we observe that relatively simple refactoring operations enable an improvement or increase in the mutation score.","tags":["Mutation Testing","Software Testing","Empirical Software Engineering"],"title":"How to Kill Them All: An Exploratory Study on the Impact of Code Observability on Mutation Testing","type":"publication"},{"authors":["Valentina Lenarduzzi","Annibale Panichella"],"categories":[],"content":"","date":1602058448,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602058448,"objectID":"82321a8e08532174d0548e5defcbd2da","permalink":"https://example.com/publication/ieee-software2020/","publishdate":"2020-10-07T10:14:08+02:00","relpermalink":"/publication/ieee-software2020/","section":"publication","summary":"Serverless architecture is an emerging design style for cloud-based software systems. Testing serverless applications plays an important role in software quality assurance. However, currently, there is no consensus on how to test and debug such systems properly. Moreover, the current lack of mature tooling is a central challenge. We designed and conducted three interviews among two tools vendor leaders in the serverless domain (Epsagon and Thundra) and one expert in the field (Yan Cui), investigating the good and bad practices and several open issues. The current status of testing and debugging in serverless-based applications depicted by the experts helped us to highlight issues and challenges that need to be deeply investigated.","tags":["Software Testing","Microservices","Serverless-based Application","Debugging"],"title":"Serverless Testing: Tool Vendors' and Experts' Point of View","type":"publication"},{"authors":null,"categories":null,"content":"","date":1601198235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601198235,"objectID":"f8dd0551c86304e9d1bebc9161b62a14","permalink":"https://example.com/talk/revisiting-test-smells-in-automatically-generated-tests-limitations-pitfalls-and-opportunities/","publishdate":"2020-09-27T11:17:15+02:00","relpermalink":"/talk/revisiting-test-smells-in-automatically-generated-tests-limitations-pitfalls-and-opportunities/","section":"event","summary":"","tags":[],"title":"Revisiting test smells in automatically generated tests: limitations, pitfalls, and opportunities","type":"event"},{"authors":["Annibale Panichella"],"categories":[],"content":"","date":1599681029,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599681029,"objectID":"9b00bb03e1bbdbab2f3953cf35dad72e","permalink":"https://example.com/publication/infsoft2020/","publishdate":"2020-09-09T21:50:29+02:00","relpermalink":"/publication/infsoft2020/","section":"publication","summary":"Context: Latent Dirichlet Allocation (LDA) has been successfully used in the literature to extract topics from software documents and support developers in various software engineering tasks. While LDA has been mostly used with default settings, previous studies showed that default hyperparameter values generate sub-optimal topics from software documents. Objective: Recent studies applied meta-heuristic search (mostly evolutionary algorithms) to configure LDA in an unsupervised and automated fashion. However, previous work advocated for different meta-heuristics and surrogate metrics to optimize. The objective of this paper is to shed light on the influence of these two factors when tuning LDA for SE tasks. Method: We empirically evaluated and compared seven state-of-the-art meta-heuristics and three alternative surrogate metrics (i.e., fitness functions) to solve the problem of identifying duplicate bug reports with LDA. The benchmark consists of ten real-world and open-source projects from the Bench4BL dataset. Results: Our results indicate that (1) meta-heuristics are mostly comparable to one another (except for random search and CMA-ES), and (2) the choice of the surrogate metric impacts the quality of the generated topics and the tuning overhead. Furthermore, calibrating LDA helps identify twice as many duplicates than untuned LDA when inspecting the top five past similar reports. Conclusion: No meta-heuristic and/or fitness function outperforms all the others, as advocated in prior studies. However, we can make recommendations for some combinations of meta-heuristics and fitness functions over others for practical use. Future work should focus on improving the surrogate metrics used to calibrate/tune LDA in an unsupervised fashion.","tags":["Topic Modeling","Latent Dirichlet Allocation","Search-based Software Engineering"," Meta-heuristics","Bug Reports","Hyperparameter optimization"],"title":"A Systematic Comparison of Search-Based Approaches for LDA Hyperparameter Tuning","type":"publication"},{"authors":["Annibale Panichella","Sebastiano Panichella","Gordon Fraser","Anand Ashok Sawant","Vincent Hellendoorn"],"categories":[],"content":"","date":1596549957,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596549957,"objectID":"a6329aaf5cd9c9d40de23ca3218e6e5f","permalink":"https://example.com/publication/icsme2020/","publishdate":"2020-08-04T16:05:57+02:00","relpermalink":"/publication/icsme2020/","section":"publication","summary":"Test smells attempt to capture design issues in test code that reduce their maintainability. Previous work found such smells to be highly common in automatically generated test-cases, but based this result on specific static detection rules; although these are based on the original definition of “test smells”, a recent empirical study showed that developers perceive these as overly strict and non-representative of the maintainability and quality of test suites. This leads us to investigate how effective such test smell detection tools are on automatically generated test suites. In this paper, we build dataset of 2,340 test cases automatically generated by EVOSUITE for 100 Java classes. We performed a multi-stage, cross-validated manual analysis to identify six types of test smells and label their instances. We benchmark the performance of two test smell detection tools: one widely used in prior work, and one recently introduced with the express goal to match developer perceptions of test smells. Our results show that these test smell detection strategies poorly characterized the issues in automatically generated test suites; the older tool’s detection strategies, especially, misclassified over 70% of test smells, both missing real instances (false negatives) and marking many smell- free tests as smelly (false positives). We identify common patterns in these tests that can be used to improve the tools, refine and update the definition of certain test smells, and highlight as of yet uncharacterized issues. Our findings suggest the need for (i) more appropriate metrics to match development practice; and (ii) more accurate detection strategies, to be evaluated primarily in industrial contexts.","tags":["Test Case Generation","Unit Testing","Test Smells","Replication Study"],"title":"Revisiting Test Smells in Automatically Generated Tests: Limitations, Pitfalls, and Opportunities","type":"publication"},{"authors":["Devjeet Roy","Ziyi Zhang","Maggie Ma","Venera Arnaoudova","Annibale Panichella","Sebastiano Panichella","Danielle Gonzalez","Mehdi Mirakhorli"],"categories":[],"content":"","date":1596140871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596140871,"objectID":"f8c407f2ea8bfc5b4fad5f4be7b6ab39","permalink":"https://example.com/publication/ase2020b/","publishdate":"2020-07-30T22:27:51+02:00","relpermalink":"/publication/ase2020b/","section":"publication","summary":"Automated test case generation tools have been successfully pro- posed to reduce the amount of human and infrastructure resources required to write and run test cases. However, recent studies demonstrate that the readability of generated tests is very limited due to (i) uninformative identifiers and (ii) lack of proper documentation. Prior studies proposed techniques to improve test readability by either generating natural language summaries or meaningful methods names. While these approaches are shown to improve test readability, they are also affected by two limitations: (1) generated summaries are often perceived as too verbose and redundant by developers, and (2) readable tests require both proper method names but also meaningful identifiers (within-method readability). In this work, we combine template based methods and Deep Learning (DL) approaches to automatically generate test case scenarios (elicited from natural language patterns of test case statements) as well as to train DL models on path-based representations of source code to generate meaningful identifier names. Our ap- proach, called DeepTC-Enhancer , recommends documentation and identifier names with the ultimate goal of enhancing readability of automatically generated test cases. An empirical evaluation with 36 external and internal developers shows that (1) DeepTC-Enhancer outperforms significantly the baseline approach for generating summaries and performs equally with the baseline approach for test case renaming, (2) the transformation proposed by DeepTC-Enhancer result in a significant increase in readability of automatically generated test cases, and (3) there is a significant difference in the feature preferences between external and internal developers.","tags":["Code Summarization","Deep Learning","Test Readability","Test Scenario","Automated Documentation"],"title":"DeepTC-Enhancer: Improving the Readability of Automatically Generated Tests","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Andy Zaidman","Arie van Deursen","A. Panichella"],"categories":[],"content":"","date":1596140866,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596140866,"objectID":"9eaa27df573f6c9ae1fa63d13347efe0","permalink":"https://example.com/publication/ase2020a/","publishdate":"2020-07-30T22:27:46+02:00","relpermalink":"/publication/ase2020a/","section":"publication","summary":"Evolutionary intelligence approaches have been successfully applied to assist developers during debugging by generating a test case reproducing reported crashes. These approaches use a single fitness function called CrashFunction to guide the search process toward reproducing a target crash. Despite the reported achievements, these approaches do not always successfully reproduce some crashes due to a lack of test diversity (premature convergence). In this study, we introduce a new approach, called MO-HO, that addresses this issue via multi-objectivization. In particular, we introduce two new Helper-Objectives for crash reproduction, namely test length (to minimize) and method sequence diversity (to maximize), in addition to CrashFunction. We assessed MO-HO using five multi-objective evolutionary algorithms (NSGA-II, SPEA2, PESA-II, MOEA/D, FEMO) on 124 hard-to-reproduce crashes stemming from open-source projects. Our results indicate that SPEA2 is the best-performing multi-objective algorithm for MO-HO. We evaluated this best-performing algorithm for MO-HO against the state-of-the-art: single-objective approach (SGGA) and decomposition-based multi-objectivization approach (decomposition). Our results show that MO-HO reproduces five crashes that cannot be reproduced by the current state-of-the-art. Besides, MO-HO improves the effectiveness (+10% and +8% in reproduction ratio) and the efficiency in 34.6% and 36% of crashes (i.e., significantly lower running time) compared to SGGA and decomposition, respectively. For some crashes, the improvements are very large, being up to +93.3% for reproduction ratio and -92% for the required running time.","tags":["Crash Replication","Test Case Generation","Search-based Software Engineering","Multi-objective Optimization","Botsing"],"title":"Good Things Come In Threes: Improving Search-based Crash Reproduction With Helper Objectives","type":"publication"},{"authors":null,"categories":null,"content":"","date":1595063835,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595063835,"objectID":"4629e6871ee99349ecf96a8e06f0b7e6","permalink":"https://example.com/talk/automated-repair-of-feature-interaction-failures-in-automated-driving-systems/","publishdate":"2020-07-18T11:17:15+02:00","relpermalink":"/talk/automated-repair-of-feature-interaction-failures-in-automated-driving-systems/","section":"event","summary":"","tags":[],"title":"Automated Repair of Feature Interaction Failures in Automated Driving Systems","type":"event"},{"authors":["Mitchell Olsthoorn","Arie van Deursen","Annibale Panichella"],"categories":[],"content":"","date":1594038590,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594038590,"objectID":"1aced2fe37781e98668ba6e93814e2a7","permalink":"https://example.com/publication/ase2020-nier/","publishdate":"2020-07-06T14:29:50+02:00","relpermalink":"/publication/ase2020-nier/","section":"publication","summary":"Software testing is an important and time-consuming task that is often done manually. In the last decades, researchers have come up with techniques to generate input data (e.g., fuzzing) and automate the process of generating test cases (e.g., search-based testing). However, these techniques are known to have their own limitations: search-based testing does not generate highly-structured data; grammar-based fuzzing does not generate test case structures. To address these limitations, we combine these two techniques. By applying grammar-based mutations to the input data gathered by the search-based testing algorithm, it allows us to co-evolve both aspects of test case generation. We evaluate our approach by performing an empirical study on 20 Java classes from the three most popular JSON parsers across multiple search budgets. Our results show that the proposed approach on average improves branch coverage for JSON related classes by 15% (with a maximum increase of 50%) without negatively impacting other classes.","tags":["Fuzzing","Test Case Generation","Search-Based Software Engineering","Many-objective Optimization","EvoSuite"],"title":"Generating Highly-structured Input Data by Combining Search-based Testing and Grammar-based Fuzzing","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Annibale Panichella","Andy Zaidman","Arie van Deursen"],"categories":[],"content":"","date":1593951593,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594037993,"objectID":"58a66d0cc70206562c4e019f40ff3ae9","permalink":"https://example.com/publication/ase2020-tool/","publishdate":"2020-07-05T14:19:53+02:00","relpermalink":"/publication/ase2020-tool/","section":"publication","summary":"Approaches for automatic crash reproduction aim to generate test cases that reproduce crashes starting from the crash stack traces. These tests help developers during their debugging practices. One of the most promising techniques in this research field leverages search-based software testing techniques for generating crash reproducing test cases. In this paper, we introduce Botsing, an open-source search-based crash reproduction framework for Java. Botsing implements state-of-the-art and novel approaches for crash reproduction. The well-documented architecture of Botsing makes it an easy-to-extend framework, and can hence be used for implementing new approaches to improve crash reproduction. We have applied Botsing to a wide range of crashes collected from open source systems. Furthermore, we conducted a qualitative assessment of the crash-reproducing test cases with our industrial partners. In both cases, Botsing could reproduce a notable amount of the given stack traces.","tags":["Search-Based Software Engineering","Crash Replication","Debugging","Botsing"],"title":"Botsing, a Search-based Crash Reproduction Framework for Java","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Annibale Panichella","Andy Zaidman","Arie van Deursen"],"categories":[],"content":"","date":1593881814,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593881814,"objectID":"5726de311f15b7842ef26d52416a014b","permalink":"https://example.com/publication/gecco2020/","publishdate":"2020-07-04T18:56:54+02:00","relpermalink":"/publication/gecco2020/","section":"publication","summary":"Evolutionary-based crash reproduction techniques aid developers in their debugging practices by generating a test case that reproduces a crash given its stack trace. In these techniques, the search process is typically guided by a single search objective called Crash Distance. Previous studies have shown that current approaches could only reproduce a limited number of crashes due to a lack of diversity in the population during the search. In this study, we address this issue by applying Multi-Objectivization using Helper-Objectives (MO-HO) on crash reproduction. In particular, we add two helper-objectives to the Crash Distance to improve the diversity of the generated test cases and consequently enhance the guidance of the search process. We assessed MO-HO against the single-objective crash reproduction. Our results show that MO-HO can reproduce two additional crashes that were not previously reproducible by the single-objective approach.","tags":["Crash Replication","Test Case Generation","Software Testing","Search-based Software Engineering"],"title":"Crash Reproduction Using Helper Objectives","type":"publication"},{"authors":["A. Panichella","J. Campos","G. Fraser"],"categories":null,"content":"","date":1587139000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587139000,"objectID":"8256a3b27d4ce54e626a9102cbf76d46","permalink":"https://example.com/publication/sbst2020/","publishdate":"2020-04-17T17:56:40+02:00","relpermalink":"/publication/sbst2020/","section":"publication","summary":"EvoSuite is a search-based tool that automatically generates executable unit tests for Java code (JUnit tests). This paper summarizes the results and experiences of EvoSuite’s participation at the eighth unit testing competition at SBST 2020, where EvoSuite achieved the highest overall score (406.14 points) for the seventh time in eight editions of the competition.","tags":["Test Case Generation","EvoSuite"],"title":"EvoSuite at the SBST 2020 Tool Competition","type":"publication"},{"authors":["Raja Ben Abdessalem","Annibale Panichella","Shiva Nejati","Lionel Briand","Thomas Stifter"],"categories":null,"content":"","date":1587137574,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587137574,"objectID":"87d6049d74ae533120a7502409ca9af9","permalink":"https://example.com/publication/issta2020/","publishdate":"2020-04-17T17:32:54+02:00","relpermalink":"/publication/issta2020/","section":"publication","summary":"The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed; for supervised ML applications, oracle information is indeed available in the form of dataset “ground truth”, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system integrity. While syntactic issues may be automatically verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for SE strategies that especially target and assess the oracle.","tags":["Self-driving Cars","Program Repair","Search-based Software Engineering"],"title":"Automated Repair of Feature Interaction Failures in Automated Driving Systems","type":"publication"},{"authors":["Carolin E. Brandt","Annibale Panichella","Andy Zaidman","Moritz Beller"],"categories":null,"content":"","date":1583251717,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583251717,"objectID":"970c6ecf48da3dd6ad1292fcfad15b6a","permalink":"https://example.com/publication/msrdata2019/","publishdate":"2020-03-03T17:08:37+01:00","relpermalink":"/publication/msrdata2019/","section":"publication","summary":"Build logs are textual by-products that a software build process creates, often as part of its Continuous Integration (CI) pipeline. Build logs are a paramount source of information for developers when debugging into and understanding a build failure. Recently, attempts to partly automate this time-consuming, purely manual activity have come up, such as rule- or information-retrieval-based techniques. We believe that having a common data set to compare different build log analysis techniques will advance the research area. It will ultimately increase our understanding of CI build failures. In this paper, we present LogChunks, a collection of 797 annotated Travis CI build logs from 80 GitHub repositories in 29 programming languages. For each build log, LogChunks contains a manually labeled log part (chunk) describing why the build failed. We externally validated the data set with the developers who caused the original build failure. The width and depth of the LogChunks data set are intended to make it the default benchmark for automated build log analysis techniques","tags":["Log Analysis","Dataset"],"title":"LogChunks: A Data Set for Build Log Analysis","type":"publication"},{"authors":["Cynthia C. S. Liem","Annibale Panichella"],"categories":null,"content":"Abstract: The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed; for supervised ML applications, oracle information is indeed available in the form of dataset “ground truth”, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system integrity. While syntactic issues may be automatically verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for SE strategies that especially target and assess the oracle.\n","date":1583248815,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583248815,"objectID":"2e85d797b28bafb67c7d817fce5bff50","permalink":"https://example.com/publication/raise2020/","publishdate":"2020-03-03T16:20:15+01:00","relpermalink":"/publication/raise2020/","section":"publication","summary":"The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed. For supervised ML applications, oracle information is indeed available in the form of dataset ‘ground truth’, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system's integrity. While syntactic issues may automatically be verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for software engineering strategies that especially target and assess the oracle.","tags":["Deep Learning","Test Oracle","Artificial Intelligence"],"title":"Oracle Issues in Machine Learning and Where to Find Them","type":"publication"},{"authors":null,"categories":null,"content":"","date":1572254235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572254235,"objectID":"e75c07b70038e196d526770a60f3ec28","permalink":"https://example.com/talk/automated-test-generation-for-unit-testing-beyond/","publishdate":"2019-10-28T11:17:15+02:00","relpermalink":"/talk/automated-test-generation-for-unit-testing-beyond/","section":"event","summary":"","tags":["test case generation","software testing","search-based software engineering"],"title":"Automated Test Generation for Unit Testing Beyond","type":"event"},{"authors":["Giovanni Grano","Christoph Laaber","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"Abstract: Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects. In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases. This study shows that performance-aware test case generation requires solving two main challenges: providing a good approximation of resource usage with minimal overhead and\navoiding detrimental effects on both final coverage and fault detection effectiveness. To tackle these challenges, we conceived a set of performance proxies -inspired by previous work on performance testing- that provide a reasonable estimation of the test execution costs (i.e., runtime and memory usage). Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing. Our empirical study -involving 110 non-trivial Java classes- reveals that our adaptive approach generates test suite with statistically significant improvements in runtime (-25%) and heap memory consumption (-15%) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness. Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.\n","date":1570607493,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570607493,"objectID":"c47926aa7591d5dcd34cab937390d6f5","permalink":"https://example.com/publication/ieee-tse2019/","publishdate":"2019-10-09T09:51:33+02:00","relpermalink":"/publication/ieee-tse2019/","section":"publication","summary":"Abstract: Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects.","tags":["Test Case Generation","Evolutionary Testing","Performance Testing","Search-based Software Engineering"],"title":"Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1569921435,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569921435,"objectID":"ff7c2c9345e51efb19df894a2f4d278f","permalink":"https://example.com/talk/testing-autonomous-cars-for-feature-interaction-failures-using-evolutionary-intelligence/","publishdate":"2019-10-01T11:17:15+02:00","relpermalink":"/talk/testing-autonomous-cars-for-feature-interaction-failures-using-evolutionary-intelligence/","section":"event","summary":"","tags":["self-driving cars","software testing","feature interactions"],"title":"Testing Autonomous Cars for Feature Interaction Failures using Evolutionary Intelligence","type":"event"},{"authors":null,"categories":null,"content":"Hugo Blox Builder is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you’ll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - blox-plugins-netlify - blox-plugins-netlify-cms - blox-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - blox-plugins-netlify - blox-plugins-netlify-cms - blox-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://docs.hugoblox.com/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/HugoBlox/hugo-blox-builder) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://docs.hugoblox.com/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/HugoBlox/hugo-blox-builder) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders as\ngantt section …","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://example.com/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Hugo Blox Builder is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Dimitri Michel Stallenberg","Annibale Panichella"],"categories":null,"content":"","date":1561538501,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561538501,"objectID":"efa028a3ccd165d576f491b24ee28681","permalink":"https://example.com/publication/esec-fse2019/","publishdate":"2019-06-26T10:41:41+02:00","relpermalink":"/publication/esec-fse2019/","section":"publication","summary":"","tags":["Security Testing","Meta-heuristics","XML-injection"],"title":"JCOMIX: A Search-Based Tool to Detect XML Injection Vulnerabilities in Web Applications","type":"publication"},{"authors":null,"categories":[],"content":"","date":1561537772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561537772,"objectID":"7ed1d0f9afe59297a980e62e87f9e3b4","permalink":"https://example.com/tools/catcher/","publishdate":"2019-06-26T10:29:32+02:00","relpermalink":"/tools/catcher/","section":"tools","summary":"Tool that combines static exception propagation and search-based software testing to automatically detect (and generate test cases) for API misuses in Java client programs.","tags":["Search-based Software Engineering","Static Analysis","API Misuse Detection"],"title":"Catcher","type":"tools"},{"authors":null,"categories":[],"content":"Towards Integration-Level Test Case Generation Using Call Site Information\n","date":1561537772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561537772,"objectID":"8a0229bec8c025b51010bd29e805c459","permalink":"https://example.com/tools/cling/","publishdate":"2019-06-26T10:29:32+02:00","relpermalink":"/tools/cling/","section":"tools","summary":"Test Case Generation for Class Integration Testing","tags":["Search-based Software Engineering","Test Case Generation","integration Testing"],"title":"Cling","type":"tools"},{"authors":null,"categories":[],"content":"A Systematic Comparison of Search Algorithms for Topic Modelling - A Study on Duplicate\rBug Report Identification\nAuthor Annibale Panichella\nVenue SSBSE 2019\nAbstract Latent Dirichlet Allocation (LDA) has been used to support\rmany software engineering tasks. Previous studies showed that default\rsettings lead to sub-optimal topic modeling with a dramatic impact\ron the performance of such approaches in terms of precision and\rrecall. For this reason, researchers used search algorithms (e.g., genetic\ralgorithms) to automatically configure topic models in an unsupervised\rfashion. While previous work showed the ability of individual search algorithms\rin finding near-optimal configurations, it is not clear to what\rextent the choice of the meta-heuristic matters for SE tasks. In this paper,\rwe present a systematic comparison of five different meta-heuristics\rto configure LDA in the context of duplicate bug reports identification.\rThe results show that (1) no master algorithm outperforms the others\rfor all software projects, (2) random search and PSO are the least effective\rmeta-heuristics. Finally, the running time strongly depends on the\rcomputational complexity of LDA while the internal complexity of the\rsearch algorithms plays a negligible role.\nGetting started The source code is available in GitHub at the link: https://github.com/apanichella/Search-Based-LDA\n","date":1561537772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561537772,"objectID":"bbe1685c369a0cb81eb9577b28a51924","permalink":"https://example.com/tools/ssbse-lda/","publishdate":"2019-06-26T10:29:32+02:00","relpermalink":"/tools/ssbse-lda/","section":"tools","summary":"R Scripts to configure LDA using meta-heuristics","tags":["Search-based Software Engineering","Meta-heuristics","Topic Model","Unsupervised Learning"],"title":"Search-Based-LDA","type":"tools"},{"authors":["Maria Kechagia","Xavier Devroey","Annibale Panichella","Georgios Gousios","Arie van Deursen"],"categories":null,"content":" Abstract : Application Programming Interfaces (APIs) typically come with (implicit) usage constraints. The violations of these constraints (API misuses) can lead to software crashes. Even though there are several tools that can detect API misuses, most of them suffer from a very high rate of false positives. We introduce Catcher, a novel API misuse detection approach that combines static exception propagation analysis with automatic search-based test case generation to effectively and efficiently pinpoint crash-prone API misuses in client applications. We validate Catcher against 21 Java applications, targeting misuses of the Java platform’s API. Our results indicate that Catcher is able to generate test cases that uncover 243 (unique) API misuses that result in crashes. Our empirical evaluation shows that Catcher can detect a large number of misuses (77 cases) that would remain undetected by the traditional coverage-based test case generator EvoSuite. Additionally, Catcher is on average eight times faster than EvoSuite in generating test cases for the identified misuses. Finally, we find that the majority of the exceptions triggered by Catcher are unexpected to developers i.e., not only unhandled in the source code but also not listed in the documentation of the client applications.\n","date":1556734971,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556734971,"objectID":"2fe58cf372a8bf8a56eef68645e340ef","permalink":"https://example.com/publication/issta2019/","publishdate":"2019-05-01T20:22:51+02:00","relpermalink":"/publication/issta2019/","section":"publication","summary":"Abstract : Application Programming Interfaces (APIs) typically come with (implicit) usage constraints. The violations of these constraints (API misuses) can lead to software crashes. Even though there are several tools that can detect API misuses, most of them suffer from a very high rate of false positives.","tags":["Search-based Software Engineering","Software Testing","Static Analysis"],"title":"Effective and Efficient API Misuse Detection via Exception Propagation and Search-based Testing","type":"publication"},{"authors":["Annibale Panichella"],"categories":null,"content":"Abstract Latent Dirichlet Allocation (LDA) has been used to support many software engineering tasks. Previous studies showed that default settings lead to sub-optimal topic modeling with a dramatic impact on the performance of such approaches in terms of precision and recall. For this reason, researchers used search algorithms (e.g., genetic algorithms) to automatically configure topic models in an unsupervised fashion. While previous work showed the ability of individual search algorithms in finding near-optimal configurations, it is not clear to what extent the choice of the meta-heuristic matters for SE tasks. In this paper, we present a systematic comparison of five different meta-heuristics to configure LDA in the context of duplicate bug reports identification. The results show that (1) no master algorithm outperforms the others for all software projects, (2) random search and PSO are the least effective meta-heuristics. Finally, the running time strongly depends on the computational complexity of LDA while the internal complexity of the search algorithms plays a negligible role.\n","date":1556572583,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556572583,"objectID":"efdf8aa40e6215036334850f1908e81f","permalink":"https://example.com/publication/ssbse2019/","publishdate":"2019-04-29T23:16:23+02:00","relpermalink":"/publication/ssbse2019/","section":"publication","summary":"Abstract Latent Dirichlet Allocation (LDA) has been used to support many software engineering tasks. Previous studies showed that default settings lead to sub-optimal topic modeling with a dramatic impact on the performance of such approaches in terms of precision and recall.","tags":["Topic Model","Search-based Software Engineering","Hyperparameter Tuning"],"title":"A Systematic Comparison of Search Algorithms for Topic Modelling - A Study on Duplicate Bug Report Identification","type":"publication"},{"authors":null,"categories":null,"content":"Title An Adaptive Evolutionary Algorithm based on Non-Euclidean Geometry for Many-objective Optimization\nAuthor Annibale Panichella\nVenue GECCO 2019\nAbstract In the last decade, several evolutionary algorithms have been proposed in the literature for solving multi- and many-objective optimization problems. The performance of such algorithms depends on their capability to produce a well-diversified front (diversity) that is as closer to the Pareto optimal front as possible (proximity). Diversity and proximity strongly depend on the geometry of the Pareto front, i.e., whether it forms a Euclidean, spherical or hyperbolic hypersurface. However, existing multi- and many-objective evolutionary algorithms show poor versatility on different geometries. To address this issue, we propose a novel evolutionary algorithm that: (1) estimates the geometry of the generated front using a fast procedure with O(MxN) computational complexity (M is the number of objectives and N is the population size); (2) adapts the diversity and proximity metrics accordingly. Therefore, to form the population for the next generation, solutions are selected based on their contribution to the diversity and proximity of the non-dominated front with regards to the estimated geometry. Computational experiments show that the proposed algorithm outperforms state-of-the-art multi and many-objective evolutionary algorithms on benchmark test problems with different geometries and number of objectives (M=3,5, and 10).\nGetting started The source code of AGE-MOEA can be downloaded: here\nAGE-MOEA is implemented as a module (algorithm) to include in the platform PlatEMO. Download the zip file (see link above) and extract its content in the folder Algorithms of PlatEMO.\n","date":1554714534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554714534,"objectID":"72f92f0d4efad050fdcc7a49f23ee247","permalink":"https://example.com/tools/age-moea/","publishdate":"2019-04-08T11:08:54+02:00","relpermalink":"/tools/age-moea/","section":"tools","summary":"Implementation of AGE-MOEA in Matlab","tags":["Many-objective Optimization","Evolutionary Computation","Matlab","Benchmark"],"title":"AGE-MOEA","type":"tools"},{"authors":["Annibale Panichella"],"categories":null,"content":"","date":1554713130,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554713130,"objectID":"b6d1f8b3fe683ac0780842d7dbdf7584","permalink":"https://example.com/publication/gecco2019/","publishdate":"2019-04-08T10:45:30+02:00","relpermalink":"/publication/gecco2019/","section":"publication","summary":"In the last decade, several evolutionary algorithms have been proposed in the literature for solving multi- and many-objective optimization problems. The performance of such algorithms depends on their capability to produce a well-diversified front (diversity) that is as closer to the Pareto optimal front as possible (proximity). Diversity and proximity strongly depend on the geometry of the Pareto front, i.e., whether it forms a Euclidean, spherical or hyperbolic hypersurface. However, existing multi- and many-objective evolutionary algorithms show poor versatility on different geometries. To address this issue, we propose a novel evolutionary algorithm that: (1) estimates the geometry of the generated front using a fast procedure with O(M × N) computational complexity (M is the number of objectives and N is the population size); (2) adapts the diversity and proximity metrics accordingly. Therefore, to form the population for the next generation, solutions are selected based on their contribution to the diversity and proximity of the non-dominated front with regards to the estimated geometry. Computational experiments show that the proposed algorithm outperforms state-of-the-art multi and many-objective evolutionary algorithms on benchmark test problems with different geometries and number of objectives (M=3,5, and 10).","tags":["Many-objective Optimization","Numerical Problems","Evolutionary Computation"],"title":"An Adaptive Evolutionary Algorithm based on Non-Euclidean Geometry for Many-objective Optimization","type":"publication"},{"authors":["José Campos","Annibale Panichella","Gordon Fraser"],"categories":null,"content":"","date":1554712910,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554712910,"objectID":"dfe2b1370f3ca9a86e68eed505e81311","permalink":"https://example.com/publication/sbst2019b/","publishdate":"2019-04-08T10:41:50+02:00","relpermalink":"/publication/sbst2019b/","section":"publication","summary":"","tags":["Test Case Generation","EvoSuite"],"title":"EvoSuite at the SBST 2019 Tool Competition","type":"publication"},{"authors":["Annibale Panichella"],"categories":null,"content":"","date":1554712743,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554712743,"objectID":"320f9ff67498056114556147a9a6884e","permalink":"https://example.com/publication/sbst2019a/","publishdate":"2019-04-08T10:39:03+02:00","relpermalink":"/publication/sbst2019a/","section":"publication","summary":"","tags":["Test Case Generation"],"title":"Beyond Unit-Testing in Search-based Test Case Generation: Challenges and Opportunities","type":"publication"},{"authors":["Sadeeq Jan","Annibale Panichella","Andrea Arcuri","Lionel Briand"],"categories":null,"content":"","date":1554711079,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554711079,"objectID":"73907a1174c90a03d99e8252001f74b1","permalink":"https://example.com/publication/emse2019/","publishdate":"2019-04-08T10:11:19+02:00","relpermalink":"/publication/emse2019/","section":"publication","summary":"","tags":["Security Testing","XML-injection","Test Case Generation","Many-objective Optimization"],"title":"Search-based Multi-Vulnerability Testing of XML Injections in Web Applications","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Hugo Blox Builder Hugo Blox Builder | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Hugo Blox Builder's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1549012635,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549012635,"objectID":"a27c2609cd5fd85b772a5abc8b4b8b96","permalink":"https://example.com/talk/speeding-up-software-testing-using-computational-intelligence/","publishdate":"2019-02-01T11:17:15+02:00","relpermalink":"/talk/speeding-up-software-testing-using-computational-intelligence/","section":"event","summary":"","tags":[],"title":"Speeding-up Software Testing using Computational intelligence","type":"event"},{"authors":["Dario Di Nucci","Annibale Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1536400262,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536400262,"objectID":"39e4cea3da0a7fda712645e31fd0069f","permalink":"https://example.com/publication/ieee-tse2018f/","publishdate":"2018-09-08T11:51:02+02:00","relpermalink":"/publication/ieee-tse2018f/","section":"publication","summary":"","tags":["Test Case Prioritization","Regression Testing","Hypervolume","Meta-heuristics"],"title":"A Test Case Prioritization Genetic Algorithm guided by the Hypervolume Indicator","type":"publication"},{"authors":["Annibale Panichella","Fitsum M. Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1534570793,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534570793,"objectID":"2744582b83c3971ea8f42c388a8fa7d9","permalink":"https://example.com/publication/infsof2018b/","publishdate":"2018-08-18T07:39:53+02:00","relpermalink":"/publication/infsof2018b/","section":"publication","summary":"","tags":["Test Case Generation","Many-objective optimization","EvoSuite"],"title":"A Large Scale Empirical Comparison of State-of-the-art Search-based Test Case Generators","type":"publication"},{"authors":["Fabio Palomba","Dario Di Nucci","Anniable Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1534180440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534180440,"objectID":"e42732a5efd57aad1dfd78180d575d90","permalink":"https://example.com/publication/infsoft2018a/","publishdate":"2018-08-13T19:14:00+02:00","relpermalink":"/publication/infsoft2018a/","section":"publication","summary":"","tags":["Code Smell","Energy Consumption","Mobile App"],"title":"On the Impact of Code Smells on the Energy Consumption of Mobile Applications","type":"publication"},{"authors":["Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1534179336,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534179336,"objectID":"604e8b3bb9980795251968610a9785df","permalink":"https://example.com/publication/ieee-tse2018e/","publishdate":"2018-08-13T18:55:36+02:00","relpermalink":"/publication/ieee-tse2018e/","section":"publication","summary":"","tags":["Crash Replication","Debugging","Meta-heuristics"],"title":"Search-Based Crash Reproduction and Its Impact on Debugging","type":"publication"},{"authors":["Annibale Panichella","Fitsum M. Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1532038074,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532038074,"objectID":"ba2dd19cace7d239e0351b069665dcab","permalink":"https://example.com/publication/ssbse2018b/","publishdate":"2018-07-20T00:07:54+02:00","relpermalink":"/publication/ssbse2018b/","section":"publication","summary":"","tags":["Test Case Generation","Search-based Software Engineering","Many-objective Optimization","EvoSuite"],"title":"Incremental Control Dependency Frontier Exploration for Many-Criteria Test Case Generation","type":"publication"},{"authors":["Mozhan Soltani","Pouria Derakhshanfar","Annibale Panichella","Xavier Devroey","Andy Zaidman","Arie van Deursen"],"categories":null,"content":"","date":1532037994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037994,"objectID":"68d33bcc1e1df9d31b6f222f7c7e8b90","permalink":"https://example.com/publication/ssbse2018a/","publishdate":"2018-07-20T00:06:34+02:00","relpermalink":"/publication/ssbse2018a/","section":"publication","summary":"","tags":["Crash Replication","Multi-objective Optimization","Debugging"],"title":"Single-objective versus Multi-Objectivized Optimization for Evolutionary Crash Reproduction","type":"publication"},{"authors":["Salma Messaoudi","Annibale Panichella","Domenico Bianculli","Lionel Briand","Raimondas Sasnauskas"],"categories":null,"content":"","date":1532037913,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037913,"objectID":"87a5a29ac12380df54f3c5a7f2f89c6b","permalink":"https://example.com/publication/icpc2018/","publishdate":"2018-07-20T00:05:13+02:00","relpermalink":"/publication/icpc2018/","section":"publication","summary":"","tags":["Log Analysis","Meta-heuristics","Search-based Software Engineering"],"title":"A Search-based Approach for Accurate Identification of Log Message Formats","type":"publication"},{"authors":["Jeroen Castelein","Mauricio Aniche","Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1532037844,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037844,"objectID":"453e29161b35199dc94a43e84bee9b11","permalink":"https://example.com/publication/icse2018/","publishdate":"2018-07-20T00:04:04+02:00","relpermalink":"/publication/icse2018/","section":"publication","summary":"","tags":["Test Case Generation","SQL","Software Testing"],"title":"Search-Based Test Data Generation for SQL Queries","type":"publication"},{"authors":["Qianqian Zhu","Annibale Panichella","Andy Zaidman"],"categories":null,"content":"","date":1532037782,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037782,"objectID":"f75b458b91a7599d8de3ff41cb1a50b5","permalink":"https://example.com/publication/icst2018/","publishdate":"2018-07-20T00:03:02+02:00","relpermalink":"/publication/icst2018/","section":"publication","summary":"","tags":["Mutation Testing","Concept Analysis"],"title":"An Investigation of Compression Techniques to Speed up Mutation Testing","type":"publication"},{"authors":["R. Abdessalem","A. Panichella","S. Nejati","L. Briand","T. Stifter"],"categories":null,"content":"","date":1532037716,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037716,"objectID":"c96bde9303e09d8bf37013044c55f26d","permalink":"https://example.com/publication/ase2018/","publishdate":"2018-07-20T00:01:56+02:00","relpermalink":"/publication/ase2018/","section":"publication","summary":"","tags":["Self-Driving Cars","Test Case Generation","Search-based Software Engineering"],"title":"Testing Autonomous Cars for Feature Interaction Failures using Many-Objective Search","type":"publication"},{"authors":["Urko R. Molina","Fitsum M. Kifetew","Annibale Panichella"],"categories":null,"content":"","date":1532037674,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037674,"objectID":"5d1c113f2c70125a81c6bae62de5d6e6","permalink":"https://example.com/publication/sbst2018/","publishdate":"2018-07-20T00:01:14+02:00","relpermalink":"/publication/sbst2018/","section":"publication","summary":"","tags":["Test Case Generation","Competition"],"title":"Java Unit Testing Tool Competition - Sixth Round","type":"publication"},{"authors":["Fabio Palomba","Annibale Panichella","Andy Zaidman","Rocco Oliveto","Andrea De Lucia"],"categories":null,"content":"","date":1531214749,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214749,"objectID":"e16ae3d544d8c8707851ac079e75b191","permalink":"https://example.com/publication/ieee-tse2018d/","publishdate":"2018-07-10T11:25:49+02:00","relpermalink":"/publication/ieee-tse2018d/","section":"publication","summary":"","tags":["Code Smell","Software Quality"],"title":"The Scent of a Smell: An Extensive Comparison between Textual and Structural Smells","type":"publication"},{"authors":["Moritz Beller","Georgios Gousios","Annibale Panichella","Sebastian Proksch","Sven Amann","Andy Zaidman"],"categories":null,"content":"","date":1531214686,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214686,"objectID":"71a21199e02b5d57f1a6febffc38594a","permalink":"https://example.com/publication/ieee-tse2018c/","publishdate":"2018-07-10T11:24:46+02:00","relpermalink":"/publication/ieee-tse2018c/","section":"publication","summary":"","tags":["Software Testing","Empirical Software Engineering"],"title":"Developer Testing in The IDE: Patterns, Beliefs, And Behavior","type":"publication"},{"authors":["Annibale Panichella","Fitsum M. Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1531214614,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214614,"objectID":"0a8267a7ff26a9e44a9f357939443e57","permalink":"https://example.com/publication/ieee-tse2018b/","publishdate":"2018-07-10T11:23:34+02:00","relpermalink":"/publication/ieee-tse2018b/","section":"publication","summary":"","tags":["Test Case Generation","Evolutionary Testing","Search-based Software Engineering","Many-objective Optimization"],"title":"Automated Test Case Generation as a Many-Objective Optimisation Problem with Dynamic Selection of the Targets","type":"publication"},{"authors":["Sadeeq. Jan","Annibale Panichella","Andrea Arcuri","Lionel Briand"],"categories":null,"content":"","date":1531214505,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214505,"objectID":"cf1be60b13298cb2b4f01a36d781c085","permalink":"https://example.com/publication/ieee-tse2018a/","publishdate":"2018-07-10T11:21:45+02:00","relpermalink":"/publication/ieee-tse2018a/","section":"publication","summary":"","tags":["Security Testing","XML-injection","Meta-heuristics"],"title":"Automatic Generation of Tests to Exploit XML Injection Vulnerabilities in Web Applications","type":"publication"},{"authors":["Dennis Appelt","Cu D. Nguyen","Annibale Panichella","Lionel Briand"],"categories":null,"content":"","date":1531213882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531213882,"objectID":"1006313693093d2fd8ce9da5112cad03","permalink":"https://example.com/publication/ieee-tr2018/","publishdate":"2018-07-10T11:11:22+02:00","relpermalink":"/publication/ieee-tr2018/","section":"publication","summary":"","tags":["Machine Learning","Security Testing","Meta-heuristics","Security Testing"],"title":"A Machine Learning- Driven Evolutionary Approach for Testing Web Application Firewalls","type":"publication"},{"authors":["Q. Zhu","A. Panichella","A. Zaidman"],"categories":null,"content":"","date":1531213882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531213882,"objectID":"c1cfb73626c50df12bab9c05742fc13a","permalink":"https://example.com/publication/stvr2018/","publishdate":"2018-07-10T11:11:22+02:00","relpermalink":"/publication/stvr2018/","section":"publication","summary":"","tags":["Mutation Testing"],"title":"A Systematic Literature Review of How Mutation Testing Supports Quality Assurance Processes","type":"publication"},{"authors":["Dario Di Nucci","Fabio Palomba","Annibale Panichella","Andy Zaidman","Andrea De Lucia,"],"categories":null,"content":"","date":1502647828,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647828,"objectID":"9a0a6ad5d54947a55eff35217a8333ba","permalink":"https://example.com/publication/saner2017b/","publishdate":"2017-08-13T20:10:28+02:00","relpermalink":"/publication/saner2017b/","section":"publication","summary":"","tags":["Code Smell","Mobile App"],"title":"Lightweight Detection of Android-specific Code Smells: the aDoctor Project","type":"publication"},{"authors":["Dario Di Nucci","Fabio Palomba","Andrea Prota","Annibale Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1502647712,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647712,"objectID":"b5d0bf5e3e64a17fbbdd1398756bdc19","permalink":"https://example.com/publication/saner2017a/","publishdate":"2017-08-13T20:08:32+02:00","relpermalink":"/publication/saner2017a/","section":"publication","summary":"","tags":["Energy Consumption","Profiling","Mobile App"],"title":"Software-Based Energy Profiling of Android Apps: Simple, Efficient and Reliable","type":"publication"},{"authors":["Qianqian Zhu","Annibale Panichella","Andy Zaidman"],"categories":null,"content":"","date":1502647608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647608,"objectID":"ee0d42b67d8129c7c79b3815a6b6a1b2","permalink":"https://example.com/publication/icstw2017/","publishdate":"2017-08-13T20:06:48+02:00","relpermalink":"/publication/icstw2017/","section":"publication","summary":"","tags":[],"title":"Speeding-Up Mutation Testing via Data Compression and State Infection","type":"publication"},{"authors":["Annibale Panichella","Urko Molina"],"categories":null,"content":"","date":1502647507,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647507,"objectID":"eb76c93ac2234bc483195d49f475cc1e","permalink":"https://example.com/publication/sbst2017/","publishdate":"2017-08-13T20:05:07+02:00","relpermalink":"/publication/sbst2017/","section":"publication","summary":"","tags":["Test Case Generation","Competition"],"title":"Java Unit Testing Tool Competition - Fifth Round","type":"publication"},{"authors":["Dario Di Nucci","Fabio Palomba","Annibale Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1502645831,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502645831,"objectID":"debdd3062b3b9c52f6d6ccd151481871","permalink":"https://example.com/publication/icse2017-tool/","publishdate":"2017-08-13T19:37:11+02:00","relpermalink":"/publication/icse2017-tool/","section":"publication","summary":"","tags":["Energy Consumption","Profiling","Mobile Apps"],"title":"PETrA: a Software-Based Tool for Estimating the Energy Profile of Android Applications","type":"publication"},{"authors":["Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1502645657,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502645657,"objectID":"ffb7a46400e38a154b5bf15f032a223b","permalink":"https://example.com/publication/icse2017/","publishdate":"2017-08-13T19:34:17+02:00","relpermalink":"/publication/icse2017/","section":"publication","summary":"","tags":["Crash Replication","Debugging","Test Case Generation"],"title":"Guided Genetic Algorithm for Automated Crash Reproduction","type":"publication"},{"authors":["Dennis Appelt","Annibale Panichella","Lionel Briand"],"categories":null,"content":"","date":1502645293,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502645293,"objectID":"4685ca945045f96fb91b0ee7e902b07b","permalink":"https://example.com/publication/issre2018/","publishdate":"2017-08-13T19:28:13+02:00","relpermalink":"/publication/issre2018/","section":"publication","summary":"","tags":[],"title":"Automatically Repairing Web Application Firewalls Based on Successful SQL Injection Attacks","type":"publication"},{"authors":["Annibale Panichella","Fitsum Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1499968982,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499968982,"objectID":"63b8e3f8a57ab1749bf9dcae3a37841d","permalink":"https://example.com/publication/ssbse2017/","publishdate":"2017-07-13T20:03:02+02:00","relpermalink":"/publication/ssbse2017/","section":"publication","summary":"","tags":["Test Case Generation","Search-based Software Engineering","EvoSuite"],"title":"LIPS vs MOSA: a Replicated Empirical Study on Automated Test Case Generation","type":"publication"},{"authors":["Annibale Panichella","Bogdan Dit","Rocco Oliveto","Massimiliano Di Penta","Denys Poshyvanyk","Andrea De Lucia"],"categories":null,"content":"","date":1471500046,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471500046,"objectID":"ec33f4ab84674c1973e52c2c61f72885","permalink":"https://example.com/publication/saner2016/","publishdate":"2016-08-18T08:00:46+02:00","relpermalink":"/publication/saner2016/","section":"publication","summary":"","tags":["Topic Model","Traceability Recovery","Debugging","Meta-heuristics"],"title":"Parameterizing and Assembling IR-based Solutions for Software Engineering Tasks using Genetic Algorithms","type":"publication"},{"authors":["Fabio Palomba","Dario Di Nucci","Annibale Panichella","Rocco Oliveto","Andrea De Lucia"],"categories":null,"content":"","date":1471499942,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499942,"objectID":"e44a2924dc15f9b7f4fe8346ee3bba7c","permalink":"https://example.com/publication/sbst2016b/","publishdate":"2016-08-18T07:59:02+02:00","relpermalink":"/publication/sbst2016b/","section":"publication","summary":"","tags":["Test Smell"],"title":"On the Diffusion of Test Smells in Automatically Generated Test Code: An Empirical Study","type":"publication"},{"authors":["Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1471499779,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499779,"objectID":"70533af01f178ca387c7055984e613ca","permalink":"https://example.com/publication/sbst2016a/","publishdate":"2016-08-18T07:56:19+02:00","relpermalink":"/publication/sbst2016a/","section":"publication","summary":"","tags":["Crash Replication","Evolutionary Testing","Test Case Generation"],"title":"Evolutionary Testing for Crash Reproduction","type":"publication"},{"authors":["M. Beller","I. Levaja","A. Panichella","G. Gousios","A. Zaidman"],"categories":null,"content":"","date":1471499655,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499655,"objectID":"e1693b47828696e413dd9da43a7d6d04","permalink":"https://example.com/publication/serip2016/","publishdate":"2016-08-18T07:54:15+02:00","relpermalink":"/publication/serip2016/","section":"publication","summary":"","tags":["Software Testing","Empirical Software Engineering"],"title":"How to Catch 'Em All: WatchDog, a Family of IDE Plug-Ins to Assess Testing","type":"publication"},{"authors":["Fabio Palomba","Annibale Panichella","Rocco Oliveto","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1471499570,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499570,"objectID":"ac4bd56debc24bb1b70783a7e676e103","permalink":"https://example.com/publication/icpc2016/","publishdate":"2016-08-18T07:52:50+02:00","relpermalink":"/publication/icpc2016/","section":"publication","summary":"","tags":["Code Smell","Information Retrieval","Software Quality"],"title":"A Textual-based Technique for Smell Detection","type":"publication"},{"authors":["C. Vassallo","F. Zampetti","D. Romano","M. Beller","A. Panichella","M. Di Penta","A. Zaidman"],"categories":null,"content":"","date":1471499470,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499470,"objectID":"f292bdc578ff461fa055aba488585ec8","permalink":"https://example.com/publication/icsme2016/","publishdate":"2016-08-18T07:51:10+02:00","relpermalink":"/publication/icsme2016/","section":"publication","summary":"","tags":["Empirical Software Engineering"],"title":"Continuous Delivery Practices in a Large Financial Organization","type":"publication"},{"authors":["Annibale Panichella","Carol V. Alexandru","Sebastiano Panichella","Alberto Bacchelli","Harald Gall"],"categories":null,"content":"","date":1471499254,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499254,"objectID":"bcbbefb00a399e754f88f796ade8c056","permalink":"https://example.com/publication/gecco2016/","publishdate":"2016-08-18T07:47:34+02:00","relpermalink":"/publication/gecco2016/","section":"publication","summary":"","tags":["Defect Prediction","Machine Learning","Meta-heuristics"],"title":"A Search-based Training Algorithm for Cost-aware Prediction","type":"publication"},{"authors":["Fabio Palomba","Annibale Panichella","Andy Zaidman","Rocco Oliveto","Andrea De Lucia"],"categories":null,"content":"","date":1471499136,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499136,"objectID":"ecc556be4c6384fba659108bf4b8c4d0","permalink":"https://example.com/publication/issta2016/","publishdate":"2016-08-18T07:45:36+02:00","relpermalink":"/publication/issta2016/","section":"publication","summary":"","tags":["Test Case Generation","Test Smell","EvoSuite"],"title":"Automatic Test Case Generation: What If Test Code Quality Matters?","type":"publication"},{"authors":["Sebastiano Panichella","Annibale Panichella","Moritz Beller","Andy Zaidman","Harald C. Gall"],"categories":null,"content":"","date":1471499006,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499006,"objectID":"1ea54cbb7420ac807bc9695196dd7e96","permalink":"https://example.com/publication/icse2016/","publishdate":"2016-08-18T07:43:26+02:00","relpermalink":"/publication/icse2016/","section":"publication","summary":"","tags":["Software Testing","Debugging","Empirical Software Engineering"],"title":"The impact of test case summaries on bug fixing performance: An empirical investigation","type":"publication"},{"authors":null,"categories":null,"content":"AI for Fintech Research (AFR) is a five year collaboration between ING and Delft University of Technology. The mission of AFR is to perform world-class research at the intersection of Artificial Intelligence, Data Analytics, and Software Analytics in the context of FinTech. AFR was launched in 2020.\nWith 36 million customers, activities in 42 countries, and a total of 50,000 employees of which 15,000 work in IT, software and data technology is at the heart of ING’s business and operations. In this context, AFR seeks to develop new AI-driven theories, methods, and tools in large scale data and software analytics.\nThe core of the AFR consists of eight research tracks, in which PhD students work on a range of topics, such as software analytics, data integration, fairness in machine learning, model life cycle management, regulatory compliance, search-based software engineering, and concept drift. In each track, researchers from TU Delft and engineers from ING are involved, as well as bachelor and master students from TU Delft.\nAFR is bi-located at the TU Delft campus in Delft and at Cumulus Park – the collaborative innovation district in Amsterdam Southeast – bringing together students, engineers, researchers, professors, and entrepreneurs from both organizations at both locations. During the COVID-19 pandemic in 2020 and 2021, all collabaration was virtual, with hybrid meetings returning in 2022.\nAFR participates in the Innovation Center for Artificial Intelligence (ICAI) as one of its labs. ICAI is a virtual organization consisting of a series of labs of similar size (over five PhD researchers each) working in close collaboration with societal or industrial partners. AFR directly benefits from the experience and expertise of other academic and industrial ICAI partners, such as Qualcomm, Bosch, Ahold Delhaize, the Dutch National Police, the University of Amsterdam, and Vrije Universiteit.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c467349eb65a7e0b05890a62bcab2c37","permalink":"https://example.com/project/afr/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/afr/","section":"project","summary":"AI for Fintech Research (AFR) is a five year collaboration between ING and Delft University of Technology. The mission of AFR is to perform world-class research at the intersection of Artificial Intelligence, Data Analytics, and Software Analytics in the context of FinTech. AFR was launched in 2020.","tags":["industry"],"title":"AI for Fintech Research","type":"project"},{"authors":null,"categories":null,"content":"The emergence of advanced AI-driven tools has led to a wide range of opportunities and transformations in software engineering practices and education. Recognizing this potential, JetBrains and Delft University of Technology have collaborated to establish the AI for Software Engineering Lab (AI4SE). Together, we are committed to conducting cutting-edge research on the impact and utilization of AI methodologies in software engineering. Our areas of focus include diverse facets of the domain, such as software development, testing, and programming education.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c9020b871e951af09961ccf99dc8920f","permalink":"https://example.com/project/ai4se/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/ai4se/","section":"project","summary":"The emergence of advanced AI-driven tools has led to a wide range of opportunities and transformations in software engineering practices and education. Recognizing this potential, JetBrains and Delft University of Technology have collaborated to establish the AI for Software Engineering Lab (AI4SE). Together, we are committed to conducting cutting-edge research on the impact and utilization of AI methodologies in software engineering. Our areas of focus include diverse facets of the domain, such as software development, testing, and programming education.","tags":["industry"],"title":"AI4SE Lab","type":"project"},{"authors":null,"categories":null,"content":"Emerging Cyber-Physical Systems (CPS)—from robotics, transportation, to medical devices—play a crucial role in the quality of life of European citizens and the future of the European economy. Increasing automation to such an extent, however, gives rise to many challenges, at the crux of which lies the hardware and software symbiosis. COSMOS proposes to overcome the strain on developing and evolving high-quality, dependable CPS by employing two key technologies: DevOps and Artificial Intelligence (AI). These technologies offer the potential to address CPS development, verification, and evolution.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"353d90c59297491e70b78ee76656e28f","permalink":"https://example.com/project/cosmos/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/cosmos/","section":"project","summary":"Emerging Cyber-Physical Systems (CPS)—from robotics, transportation, to medical devices—play a crucial role in the quality of life of European citizens and the future of the European economy. Increasing automation to such an extent, however, gives rise to many challenges, at the crux of which lies the hardware and software symbiosis. COSMOS proposes to overcome the strain on developing and evolving high-quality, dependable CPS by employing two key technologies, namely DevOps and Artificial Intelligence (AI). These technologies offer the potential to address CPS development, verification, and evolution.","tags":["european"],"title":"DevOps for Complex Cyber-physical Systems","type":"project"},{"authors":null,"categories":null,"content":"STAMP stands for Software Testing AMPlification. Leveraging advanced research in automatic test generation, STAMP aims at pushing automation in DevOps one step further through innovative methods of test amplification. STAMP will reuse existing assets (test cases, API descriptions, dependency models), in order to generate more test cases and test configurations each time the application is updated.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"89739a589c1812fae13a295e3f6e4d8e","permalink":"https://example.com/project/stamp/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/stamp/","section":"project","summary":"STAMP stands for Software Testing AMPlification. Leveraging advanced research in automatic test generation, STAMP aims at pushing automation in DevOps one step further through innovative methods of test amplification. STAMP will reuse existing assets (test cases, API descriptions, dependency models), in order to generate more test cases and test configurations each time the application is updated.","tags":["european"],"title":"STAMP: Software Testing Amplification for DevOps","type":"project"},{"authors":null,"categories":null,"content":"UBRI is a partnership between Ripple and top universities around the world to support academic research, technical development and innovation in blockchain, cryptocurrency and , digital payments. Ripple is providing both financial and technical resources to university partners and collaborates with faculty and students on research and technical projects.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"cbbe6120daaf56f71f2a4298d23030dc","permalink":"https://example.com/project/ubri/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/ubri/","section":"project","summary":"UBRI is a partnership between Ripple and top universities around the world to support academic research, technical development and innovation in blockchain, cryptocurrency and , digital payments. Ripple is providing both financial and technical resources to university partners and collaborates with faculty and students on research and technical projects.","tags":["industry"],"title":"UBRI: University Blockchain Research Initiative","type":"project"},{"authors":["G. Canfora","A. De Lucia","M. Di Penta","R. Oliveto","A. Panichella","S. Panichella"],"categories":null,"content":"","date":1437342641,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437342641,"objectID":"8a037fb6dff481ee5695a14d2aacaa6e","permalink":"https://example.com/publication/stvr2015/","publishdate":"2015-07-19T23:50:41+02:00","relpermalink":"/publication/stvr2015/","section":"publication","summary":"","tags":["Defect Prediction","Multi-objective Optimization","Machine Learning"],"title":"Defect Prediction as a Multi-Objective Optimization Problem","type":"publication"},{"authors":["Annibale Panichella","Rocco Oliveto","Massimiliano Di Penta","Andrea De Lucia"],"categories":null,"content":"Abstract: A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.\n","date":1437342396,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437342396,"objectID":"1c0deac416dc345f999b5fdf953acd9e","permalink":"https://example.com/publication/tse2015/","publishdate":"2015-07-19T23:46:36+02:00","relpermalink":"/publication/tse2015/","section":"publication","summary":"Abstract: A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem.","tags":["Regression Testing","Search-based Software Engineering","Test Case Selection"],"title":"Improving Multi-Objective Search Based Test Suite Optimization through Diversity Injection","type":"publication"},{"authors":["Andrea De Lucia","Massimiliano Di Penta","Rocco Oliveto","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1405806774,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405806774,"objectID":"cc270ace894d74074b08767f42ddf9d7","permalink":"https://example.com/publication/emse2014/","publishdate":"2014-07-19T23:52:54+02:00","relpermalink":"/publication/emse2014/","section":"publication","summary":"","tags":["Information Retrieval","Topic Model","Empirical Software Engineering"],"title":"Labeling Source Code with Information Retrieval Methods: An Empirical Study.","type":"publication"},{"authors":["Giovanni Capobianco","Andrea De Lucia","Rocco Oliveto","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1342734949,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1342734949,"objectID":"c77e6b4ed38050ad83b9577eb3041f5b","permalink":"https://example.com/publication/jse2012/","publishdate":"2012-07-19T23:55:49+02:00","relpermalink":"/publication/jse2012/","section":"publication","summary":"","tags":["Information Retrieval","Traceability Recovery"],"title":"Improving IR-based traceability recovery via noun-based indexing of software artifacts","type":"publication"},{"authors":["Andrea De Lucia","Massimiliano Di Penta","Rocco Oliveto","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1342734859,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1342734859,"objectID":"23c663d9beb777bc3a2265e251f7cf52","permalink":"https://example.com/publication/infsoft/","publishdate":"2012-07-19T23:54:19+02:00","relpermalink":"/publication/infsoft/","section":"publication","summary":"","tags":["Information Retrieval","Traceability Recovery","Smoothing Filter"],"title":"Applying a Smoothing Filter to Improve IR-based Traceability Recovery Processes: An Empirical Investigation.","type":"publication"}]
[{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor in the Software Engineering Research Group (SERG) at Delft University of Technology (TU Delft) in the Netherlands. I am the head of the Computation Intelligence for Software Engineering Lab (CISELab) within SERG. My research interests include security testing, software testing, search-based software engineering, testing for AI, empirical software engineering. I serve and have served as a program committee member of various international conferences (e.g., ICSE, ESEC/FSE, ISSTA, GECCO, ICST) and as a reviewer for various international journals (e.g., TSE, TOSEM, TEVC, EMSE, STVR) in the fields of software engineering and evolutionary computation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/annibale-panichella/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/annibale-panichella/","section":"authors","summary":"I am an Assistant Professor in the Software Engineering Research Group (SERG) at Delft University of Technology (TU Delft) in the Netherlands. I am the head of the Computation Intelligence for Software Engineering Lab (CISELab) within SERG.","tags":null,"title":"Annibale Panichella","type":"authors"},{"authors":["Annibale Panichella","Sebastiano Panichella","Gordon Fraser","Anand Ashok Sawant","Vincent Hellendoorn"],"categories":[],"content":"","date":1658396054,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658396054,"objectID":"d89ea7d71b593897d1775a1537572538","permalink":"/publication/emse2022/","publishdate":"2022-07-21T11:34:14+02:00","relpermalink":"/publication/emse2022/","section":"publication","summary":"Test smells aim to capture design issues in test code that reduces its maintainability. These have been extensively studied and generally found quite prevalent in both human-written and automatically generated test-cases. However, most evidence of prevalence is based on specific static detection rules. Although those are based on the original, conceptual definitions of the various test smells, recent empirical studies indicate that developers perceive warnings raised by detection tools as overly strict and non-representative of the maintainability and quality of test suites. This leads us to re-assess test smell detection tools' detection accuracy and investigate the prevalence and detectability of test smells more broadly. Specifically, we construct a hand-annotated dataset spanning hundreds of test suites both written by developers and generated by two test generation tools (EvoSuite and JTExpert) and performed a multi-stage, cross-validated manual analysis to identify the presence of six types of test smells in these. We then use this manual labeling to benchmark the performance and external validity of two test smell detection tools -- one widely used in prior work and one recently introduced with the express goal to match developer perceptions of test smells. Our results primarily show that the current vocabulary of test smells is highly mismatched to real concerns: multiple smells were ubiquitous on developer-written tests but virtually never correlated with semantic or maintainability flaws; machine-generated tests actually often scored better, but in reality, suffered from a host of problems not well-captured by current test smells. Current test smell detection strategies poorly characterized the issues in these automatically generated test suites; in particular, the older tool's detection strategies misclassified over 70% of test smells, both missing real instances (false negatives) and marking many smell-free tests as smelly (false positives). We identify common patterns in these tests that can be used to improve the tools, refine and update the definition of certain test smells, and highlight as of yet uncharacterized issues. Our findings suggest the need for (i) more appropriate metrics to match development practice, (ii) more accurate detection strategies to be evaluated primarily in industrial contexts.","tags":["Test Case Generation","Unit Testing","Test Smells","Replication Study"],"title":"Test Smells 20 Years Later: Detectability, Validity, and Reliability","type":"publication"},{"authors":["Mitchell Olsthoorn","Arie van Deursen","Annibale Panichella"],"categories":[],"content":"","date":1654965828,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654965828,"objectID":"b46b5a48499bf8138c3dc849da11a5f3","permalink":"/publication/icsme2022/","publishdate":"2022-06-11T18:43:48+02:00","relpermalink":"/publication/icsme2022/","section":"publication","summary":"Transaction-reverting statements are key constructs within Solidity that are extensively used for authority and validity checks. Current state-of-the-art search-based testing and fuzzing approaches do not explicitly handle these statements and therefore can not effectively detect security vulnerabilities. In this paper, we argue that it is critical to directly handle and test these statements to assess that they correctly protect the contracts against invalid requests. To this aim, we propose a new approach that improves the search guidance for these transaction-reverting statements based on interprocedural control dependency analysis, in addition to the traditional coverage criteria. We assess the benefits of our approach by performing an empirical study on 100 smart contracts w.r.t. transaction-reverting statement coverage and vulnerability detection capability. Our results show that the proposed approach can improve the performance of DynaMOSA, the state-of-the-art algorithm for test case generation. On average, we improve transaction-reverting statement coverage by 14 % (up to 35 %), line coverage by 8 % (up to 32 %), and vulnerability-detection capability by 17 % (up to 50 %).","tags":["Test Case Generation","Fuzzing","Smart Contracts","Search-based Software Engineering"],"title":"Guiding Automated Test Case Generation for Transaction-Reverting Statements in Smart Contracts","type":"publication"},{"authors":["Christian Birchler","Sajad Khatiri","Pouria Derakhshanfar","Sebastiano Panichella","Annibale Panichella"],"categories":null,"content":"","date":1649064105,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649064105,"objectID":"026c9cebe722dee45f37135747b2c5db","permalink":"/publication/acm-tosem2022/","publishdate":"2022-04-04T11:21:45+02:00","relpermalink":"/publication/acm-tosem2022/","section":"publication","summary":"","tags":["Self-driving Cars","Regression Testing","Multi-objective Optimization","Search-based Software Engineering"],"title":"Single and Multi-objective Test Cases Prioritization for Self-driving Cars in Virtual Environments","type":"publication"},{"authors":["Annibale Panichella"],"categories":null,"content":"","date":1648371404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648371404,"objectID":"1d6fbf4a9e41579eef76a49fb42150a4","permalink":"/publication/gecco2022/","publishdate":"2022-03-27T10:56:44+02:00","relpermalink":"/publication/gecco2022/","section":"publication","summary":"A key idea in many-objective optimization is to approximate the optimal Pareto front using a set of representative non-dominated solutions. The produced solution set should be close to the optimal front (convergence) and well-diversified (diversity). Recent studies have shown that measuring both convergence and diversity depends on the shape (or curvature) of the Pareto front. In recent years, researchers have proposed evolutionary algorithms that model the shape of the non-dominated front to define environmental selection strategies that adapt to the underlying geometry. This paper proposes a novel method for non-dominated front modeling using the Newton-Raphson iterative method for roots finding. Second, we compute the distance (diversity) between each pair of non-dominated solutions using geodesics, which are generalizations of the distance on Riemann manifolds (curved topological spaces). Thereafter, we have introduced an evolutionary algorithm within the Adaptive Geometry Estimation based MOEA (AGE-MOEA) framework, which we called AGE-MOEA-II. Computational experiments with 17 problems from the WFG and SMOP benchmarks show that AGE-MOEA-II outperforms its predecessor AGE-MOEA as well as other state-of-the-art many-objective algorithms, i.e., NSGA-III, MOEA/D, VaEA, and LMEA.","tags":["Many-objective Optimization","Numerical Problems","Evolutionary Computation"],"title":"An Improved Pareto Front Modeling Algorithm for Large-scale Many-Objective Optimization","type":"publication"},{"authors":null,"categories":null,"content":"","date":1647595035,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647595035,"objectID":"e5417fd05acba89691601113a90dc3e0","permalink":"/talk/svt2022/","publishdate":"2022-03-18T11:17:15+02:00","relpermalink":"/talk/svt2022/","section":"talk","summary":"","tags":[],"title":"Do Tests Generated by AI Help Developers? Open Challenges, Applications, and Opportunities","type":"talk"},{"authors":["Mitchell Olsthoorn ","Dimitri Stallenberg","Arie van Deursen","Annibale Panichella"],"categories":[],"content":"","date":1642508990,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642508990,"objectID":"040fac553c24c3e9d3d6bfe79975828c","permalink":"/publication/icse-demo2022/","publishdate":"2022-01-18T14:29:50+02:00","relpermalink":"/publication/icse-demo2022/","section":"publication","summary":"Ethereum is the largest and most prominent smart contract platform. One key property of Ethereum is that once a contract is deployed, it can not be updated anymore. This increases the importance of thoroughly testing the behavior and constraints of the smart contract before deployment. Existing approaches in related work either do not scale or are only focused on finding crashing inputs. In this tool demo, we introduce SynTest-Solidity, an automated test case generation and fuzzing framework for Solidity. SynTest-Solidity implements various metaheuristic search algorithms, including random search (traditional fuzzing) and genetic algorithms (i.e., NSGA-II, MOSA, and DynaMOSA). Finally, we performed a preliminary empirical study to assess the effectiveness of SynTest-Solidity in testing Solidity smart contracts.","tags":["Fuzzing","Test Case Generation","Smart Contracts","Testing"],"title":"SynTest-Solidity: Automated Test Case Generation and Fuzzing for Smart Contracts","type":"publication"},{"authors":["Giuseppe Di Domenico","Dror Weisman","Annibale Panichella","Dolev Roitman","Ady Arie"],"categories":[],"content":"","date":1641027451,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639990651,"objectID":"3a221bb6ff048adff98593cc06de714d","permalink":"/publication/acsphotonics2022/","publishdate":"2022-01-01T09:57:31+01:00","relpermalink":"/publication/acsphotonics2022/","section":"publication","summary":"","tags":["Clustering","Machine Learning","Evolutionary Algorithms","On-chip Sorting","Hermite-Gaussian beams"],"title":"Large scale inverse design of planar on-chip mode sorter","type":"publication"},{"authors":["Matthías Páll Gissurarson","Leonhard Applis","Annibale Panichella","Arie van Deursen","David Sands"],"categories":[],"content":"","date":1641025959,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639989159,"objectID":"7cdfe2d93c7fb175db17d96d1e8d6b07","permalink":"/publication/icse2022/","publishdate":"2022-01-01T09:32:39+01:00","relpermalink":"/publication/icse2022/","section":"publication","summary":"Automatic program repair (APR) regularly faces the challenge of overfitting patches that pass the test suite, but do not actually address the problems when evaluated manually. Currently, overfit detection requires manual inspection or an oracle making quality control of APR an expensive task. With this work, we want to introduce properties in addition to unit tests for APR to address the problem of overfitting. To that end, we design and implement PropR, a program repair tool for Haskell that leverages both property-based testing (via QuickCheck) and the rich type system and synthesis offered by the Haskell compiler. We compare the repair-ratio, time-to-first-patch and overfitting-ratio when using unit tests, property-based tests, and their combination. Our results show that properties lead to quicker results and have a lower overfit ratio than unit tests. The created overfit patches provide valuable insight into the underlying problems of the program to repair (e.g., in terms of fault localization or test quality). We consider this step towards fitter, or at least insightful, patches a critical contribution to bring APR into developer workflows.","tags":["Program Repair","Property","Genetic Programming","Haskell"],"title":"PropR: Property-Based Automatic Program Repair","type":"publication"},{"authors":["Leonhard Applis","Annibale Panichella","Arie van Deursen"],"categories":[],"content":"","date":1628368071,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628368071,"objectID":"4441a5d69b97f3bb7e96e293d3a20bc4","permalink":"/publication/ase2021-nier/","publishdate":"2021-08-07T22:27:51+02:00","relpermalink":"/publication/ase2021-nier/","section":"publication","summary":"Metamorphic testing is a well-established testing technique that has been successfully applied in various domains, including testing deep learning models to assess their robustness against data noise or malicious input. Currently, metamorphic testing approaches for machine learning (ML) models focused on image processing and object recognition tasks. Hence, these approaches cannot be applied to ML targeting program analysis tasks. In this paper, we extend metamorphic testing approaches for ML models targeting software programs. We present Lampion, a novel testing framework that applies (semantics preserving) metamorphic transformations on the test datasets. Lampion produces new code snippets equivalent to the original test set but different in their identifiers or syntactic structure. We evaluate Lampion against CodeBERT, a state-of-the-art ML model for Code-To-Text tasks that creates Javadoc summaries for given Java methods. Our results show that simple transformations significantly impact the target model behavior, providing additional information on the models reasoning apart from the classic performance metric.","tags":["Metamorphic testing","Machine Learning","Deep Learning","AI for SE"],"title":"\tAssessing Robustness of ML-Based Program Analysis Tools using Metamorphic Program Transformations","type":"publication"},{"authors":["Dimitri Stallenberg","Mitchell Olsthoorn","Annibale Panichella"],"categories":[],"content":"","date":1625689671,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625689671,"objectID":"fd843d1bc3180fa73faab6df3e297bb4","permalink":"/publication/ase2021/","publishdate":"2021-07-07T22:27:51+02:00","relpermalink":"/publication/ase2021/","section":"publication","summary":"Automated test case generation tools have been successfully pro- posed to reduce the amount of human and infrastructure resources required to write and run test cases. However, recent studies demonstrate that the readability of generated tests is very limited due to (i) uninformative identifiers and (ii) lack of proper documentation. Prior studies proposed techniques to improve test readability by either generating natural language summaries or meaningful methods names. While these approaches are shown to improve test readability, they are also affected by two limitations: (1) generated summaries are often perceived as too verbose and redundant by developers, and (2) readable tests require both proper method names but also meaningful identifiers (within-method readability). In this work, we combine template based methods and Deep Learning (DL) approaches to automatically generate test case scenarios (elicited from natural language patterns of test case statements) as well as to train DL models on path-based representations of source code to generate meaningful identifier names. Our ap- proach, called DeepTC-Enhancer , recommends documentation and identifier names with the ultimate goal of enhancing readability of automatically generated test cases. An empirical evaluation with 36 external and internal developers shows that (1) DeepTC-Enhancer outperforms significantly the baseline approach for generating summaries and performs equally with the baseline approach for test case renaming, (2) the transformation proposed by DeepTC-Enhancer result in a significant increase in readability of automatically generated test cases, and (3) there is a significant difference in the feature preferences between external and internal developers.","tags":["Test Case Generation","Clustering","Machine Learning","EvoMaster","RESTful API"],"title":"Improving Test Case Generation for REST APIs Through Hierarchical Clustering","type":"publication"},{"authors":["Mitchell Olsthoorn","Pouria Derakhshanfar","Annibale Panichella"],"categories":null,"content":"Abstract State-of-the-art search-based approaches for test case generation work at test case level, where tests are represented as sequences of statements. These approaches make use of genetic operators (i.e., mutation and crossover) that create test variants by adding, altering, and removing statements from existing tests. While this encoding schema has been shown to be very effective for many-objective test case generation, the standard crossover operator (single-point) only alters the structure of the test cases but not the input data. In this paper, we argue that changing both the test case structure and the input data is necessary to increase the genetic variation and improve the search process. Hence, we propose a hybrid multi-level crossover (HMX) operator that combines the traditional test-level crossover with data-level recombination. The former evolves and alters the test case structures, while the latter evolves the input data using numeric and string-based recombinational operators. We evaluate our new crossover operator by performing an empirical study on more than 100 classes selected from open-source Java libraries for numerical operations and string manipulation. We compare HMX with the single-point crossover that is used in EvoSuite w.r.t structural coverage and fault detection capability. Our results show that HMX achieves a statistically significant increase in 30% of the classes up to 19% in structural coverage compared to the single-point crossover. Moreover, the fault detection capability improved up to 12% measured using strong mutation score.\n","date":1624950983,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624950983,"objectID":"83ccee878cd62cc649ec029f7211f77c","permalink":"/publication/ssbse2021b/","publishdate":"2021-06-29T09:16:23+02:00","relpermalink":"/publication/ssbse2021b/","section":"publication","summary":"Abstract State-of-the-art search-based approaches for test case generation work at test case level, where tests are represented as sequences of statements. These approaches make use of genetic operators (i.e., mutation and crossover) that create test variants by adding, altering, and removing statements from existing tests.","tags":["Test Case Generation","Many-objective Optimization","EvoSuite"],"title":"Hybrid Multi-level Crossover for Unit Test Case Generation","type":"publication"},{"authors":["Mitchell Olsthoorn","Annibale Panichella"],"categories":null,"content":"Abstract Test case selection (TCS) aims to select a subset of the test suite to run for regression testing. The selection is typically based on past coverage and execution cost data. Researchers have successfully used multi-objective evolutionary algorithms (MOEAs), such as NSGA-II and its variants, to solve the problem. These MOEAs use traditional crossovers to create new candidate solutions during the search. Recent studies in evolutionary computation showed that more effective recombinations can be made by using linkage learning. Inspired by these recent advances in this field, we propose a new variant of NSGA-II, called L2-NSGA, that uses linkage learning to optimize test case selection. In particular, we use an unsupervised clustering algorithm to infer promising patterns among the solutions (sub-test suites). Then, these patterns are used in the next iterations of L2-NSGA to create solutions that contain/preserve these inferred patterns. Our results show that our customizations make NSGA-II more effective for test case selection. Furthermore, the test suite sub-sets generated by L2-NSGA are less expensive and more effective (detect more faults) than those generated by MOEAs used in the literature for regression testing.\n","date":1624950983,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624950983,"objectID":"3fdde29bf1a1b355ac09cd386e9fd315","permalink":"/publication/ssbse2021a/","publishdate":"2021-06-29T09:16:23+02:00","relpermalink":"/publication/ssbse2021a/","section":"publication","summary":"Abstract Test case selection (TCS) aims to select a subset of the test suite to run for regression testing. The selection is typically based on past coverage and execution cost data.","tags":["Regression Testing","Machine Learning","Multi-objective Optimization","Search-based Software Engineering","Test Case Selection"],"title":"Multi-objective Test Case Selection Through Linkage Learning-driven Crossover","type":"publication"},{"authors":null,"categories":null,"content":"","date":1622107035,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622107035,"objectID":"78322ffff352d7cf3490ae864903f8fe","permalink":"/talk/icse-nier2021/","publishdate":"2021-05-27T11:17:15+02:00","relpermalink":"/talk/icse-nier2021/","section":"talk","summary":"","tags":["Mutation Testing","Deep Learning"],"title":"What Are We Really Testing in Mutation Testing for Machine Learning? A Critical Reflection","type":"talk"},{"authors":["Salma Messaoudi","Donghwan Shin","Annibale Panichella","Domenico Bianculli","Lionel Briand"],"categories":null,"content":"","date":1618815836,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618815836,"objectID":"9be3039c9c1cd9613478915f04c0242a","permalink":"/publication/issta2021/","publishdate":"2021-04-19T09:03:56+02:00","relpermalink":"/publication/issta2021/","section":"publication","summary":"Regression testing is arguably one of the most important activities in software testing. However, its cost-effectiveness and usefulness can be largely impaired by complex system test cases that are poorly designed (e.g., test cases containing  multiple test scenarios combined into a single test case) and that require a large amount of time and resources to run.  One way to mitigate this issue is decomposing such system test cases into smaller, separate test cases---each of them with only one test scenario and with its corresponding assertions---so that the execution time of the decomposed test cases is lower than the original test cases, while the test effectiveness of the original test cases is preserved. This decomposition can be achieved with program slicing techniques, since test cases are software programs too. However, existing static and dynamic slicing techniques exhibit limitations when (1) the test cases use external resources, (2) code instrumentation is not a viable option, and (3) test execution is expensive.  In this paper, we propose a novel approach, called DS3 (Decomposing System teSt caSe), which automatically decomposes a complex system test case into separate test case slices. The idea is to use test case execution logs, obtained from past regression testing sessions, to identify ``hidden'' dependencies in the slices generated by static slicing. Since logs include run-time information about the system under test, we can use them to extract access and usage of global resources and refine the slices generated by static slicing.  We evaluated DS3 in terms of slicing effectiveness and compared it with a vanilla static slicing tool. We also compared the slices obtained by DS3 with the corresponding original system test cases, in terms of test efficiency and effectiveness. The evaluation results on one proprietary system and one open-source system show that DS3 is able to accurately identify the dependencies related to the usage of global resources, which vanilla static slicing misses. Moreover, the generated test case slices are, on average, 3.56 times faster than original system test cases and they exhibit no significant loss in terms of fault detection effectiveness.","tags":["Log Analysis","Test case slicing","Regression Testing","Software Testing","Test Smell"],"title":"Log-based Slicing for System-level Test Cases","type":"publication"},{"authors":["S. Vogl","S. Schweikl","G. Fraser","A. Arcuri","J. Campos","A. Panichella"],"categories":null,"content":"","date":1617292600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617292600,"objectID":"f0bef738ea1b1c30edbaa59702751c92","permalink":"/publication/sbst2021/","publishdate":"2021-04-01T17:56:40+02:00","relpermalink":"/publication/sbst2021/","section":"publication","summary":"EvoSuite is a search-based tool that automatically generates executable unit tests for Java code (JUnit tests). This paper summarises the results and experiences of EvoSuite participation at the ninth unit testing competition at SBST 2021, where EvoSuite achieved the highest overall score.","tags":["Test Case Generation","EvoSuite"],"title":"EvoSuite at the SBST 2021 Tool Competition","type":"publication"},{"authors":["Annibale Panichella","Cynthia C. S. Liem"],"categories":[],"content":"","date":1610972990,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579350590,"objectID":"9a7acffa695edc5e6117d9c066e0e56e","permalink":"/publication/icse-nier2020/","publishdate":"2021-01-18T14:29:50+02:00","relpermalink":"/publication/icse-nier2020/","section":"publication","summary":"Mutation testing is a well-established technique for assessing a test suite's effectiveness by injecting artificial faults into production code. In recent years, mutation testing has been extended to machine learning (ML) systems and deep learning (DL) in particular. Researchers have proposed approaches, tools, and statistically sound heuristics to determine whether mutants in DL systems are killed or not. However, as we will argue in this work, questions can be raised to what extent currently used mutation testing techniques in DL are actually in line with the classical interpretation of mutation testing. As we will discuss, in current approaches, the distinction between production and test code is blurry, the realism of mutation operators can be challenged, and generally, the degree to which the hypotheses underlying classical mutation testing (competent programmer hypothesis and coupling effect hypothesis) are followed lacks focus and explicit mappings. In this paper, we observe that ML model development follows a test-driven development (TDD) process, where data points (test data) with labels (implicit assertions) correspond to test cases in traditional software. Based on this perspective, we critically revisit existing mutation operators for ML, the mutation testing paradigm for ML, and its fundamental hypotheses. Based on our observations, we propose several action points for better alignment of mutation testing techniques for ML with paradigms and vocabularies of classical mutation testing.","tags":["Fuzzing","Mutation Testing","Machine Learning","Software Testing","Deep Learning"],"title":"What Are We Really Testing in Mutation Testing for Machine Learning? A Critical Reflection","type":"publication"},{"authors":["Casper Schroder","A. van der Feltz","Annibale Panichella","Mauricio Aniche"],"categories":[],"content":"","date":1609532871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577910471,"objectID":"1e5fce5155268b75032e69cc895eca7e","permalink":"/publication/icse-seip2020/","publishdate":"2021-01-01T22:27:51+02:00","relpermalink":"/publication/icse-seip2020/","section":"publication","summary":"","tags":["Refactoring","Search-based Software Engineering","Software Quality"],"title":"Search-Based Software Re-Modularization: A Case Study at Adyen","type":"publication"},{"authors":["B. Yildiz","H. Hung","J. H. Krijthe","C. C. S. Liem","M. Loog","G. Migut","F. Oliehoek","A. Panichella","P. Paweczak","S. Picek","M. de Weerdt","J. van Gemert"],"categories":null,"content":"","date":1609515174,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609515174,"objectID":"fd36b0cde9bc5a5da3c336c68ccb0fac","permalink":"/publication/rrpr2021/","publishdate":"2021-01-01T17:32:54+02:00","relpermalink":"/publication/rrpr2021/","section":"publication","summary":"We present ReproducedPaper.org: an open online repository for teaching and structuring machine learning reproducibility. We evaluate doing a reproduction project among students and the added value of an online reproduction repository among AI researchers. We use  anonymous self-assessment surveys and obtained 144 responses. Results suggest that students who do a reproduction project place more value on scientific reproductions and become more critical thinkers.  Students and AI researchers agree that our online reproduction repository is valuable.","tags":["Machine Learning","Reproducibility"],"title":"ReproducedPaper.org: Openly teaching and structuring machine learning reproducibility","type":"publication"},{"authors":["Qianqian Zhou","Andy Zaidman","Annibale Panichella"],"categories":null,"content":"","date":1606836774,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606836774,"objectID":"d71fd0a87b526da4df57f23dd76471cc","permalink":"/publication/jss2020/","publishdate":"2020-12-01T17:32:54+02:00","relpermalink":"/publication/jss2020/","section":"publication","summary":"Mutation testing is well-known for its efficacy in assessing test quality, and starting to be applied in the industry. However, what should a developer do when confronted with a low mutation score? Should the test suite be plainly reinforced to increase the mutation score, or should the production code be improved as well, to make the creation of better tests possible? In this paper, we aim to provide a new perspective to developers that enables them to understand and reason about the mutation score in the light of testability and observability. First, we investigate whether testability and observability metrics are correlated with the mutation score on six open-source Java projects. We observe a correlation between observability metrics and the mutation score, e.g., test directness, which measures the extent to which the production code is tested directly, seems to be an essential factor. Based on our insights from the correlation study, we propose a number of ''mutation score anti-patterns''', enabling software engineers to refactor their existing code or add tests to improve the mutation score. In doing so, we observe that relatively simple refactoring operations enable an improvement or increase in the mutation score.","tags":["Mutation Testing","Software Testing","Empirical Software Engineering"],"title":"How to Kill Them All: An Exploratory Study on the Impact of Code Observability on Mutation Testing","type":"publication"},{"authors":["Valentina Lenarduzzi","Annibale Panichella"],"categories":[],"content":"","date":1602058448,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602058448,"objectID":"82321a8e08532174d0548e5defcbd2da","permalink":"/publication/ieee-software2020/","publishdate":"2020-10-07T10:14:08+02:00","relpermalink":"/publication/ieee-software2020/","section":"publication","summary":"Serverless architecture is an emerging design style for cloud-based software systems. Testing serverless applications plays an important role in software quality assurance. However, currently, there is no consensus on how to test and debug such systems properly. Moreover, the current lack of mature tooling is a central challenge. We designed and conducted three interviews among two tools vendor leaders in the serverless domain (Epsagon and Thundra) and one expert in the field (Yan Cui), investigating the good and bad practices and several open issues. The current status of testing and debugging in serverless-based applications depicted by the experts helped us to highlight issues and challenges that need to be deeply investigated.","tags":["Software Testing","Microservices","Serverless-based Application","Debugging"],"title":"Serverless Testing: Tool Vendors' and Experts' Point of View","type":"publication"},{"authors":null,"categories":null,"content":"","date":1601198235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601198235,"objectID":"92fce2915da46ca4138a9173a2082d83","permalink":"/talk/icsme2020/","publishdate":"2020-09-27T11:17:15+02:00","relpermalink":"/talk/icsme2020/","section":"talk","summary":"","tags":[],"title":"Revisiting test smells in automatically generated tests: limitations, pitfalls, and opportunities","type":"talk"},{"authors":["Annibale Panichella"],"categories":[],"content":"","date":1599681029,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599681029,"objectID":"9b00bb03e1bbdbab2f3953cf35dad72e","permalink":"/publication/infsoft2020/","publishdate":"2020-09-09T21:50:29+02:00","relpermalink":"/publication/infsoft2020/","section":"publication","summary":"Context: Latent Dirichlet Allocation (LDA) has been successfully used in the literature to extract topics from software documents and support developers in various software engineering tasks. While LDA has been mostly used with default settings, previous studies showed that default hyperparameter values generate sub-optimal topics from software documents. Objective: Recent studies applied meta-heuristic search (mostly evolutionary algorithms) to configure LDA in an unsupervised and automated fashion. However, previous work advocated for different meta-heuristics and surrogate metrics to optimize. The objective of this paper is to shed light on the influence of these two factors when tuning LDA for SE tasks. Method: We empirically evaluated and compared seven state-of-the-art meta-heuristics and three alternative surrogate metrics (i.e., fitness functions) to solve the problem of identifying duplicate bug reports with LDA. The benchmark consists of ten real-world and open-source projects from the Bench4BL dataset. Results: Our results indicate that (1) meta-heuristics are mostly comparable to one another (except for random search and CMA-ES), and (2) the choice of the surrogate metric impacts the quality of the generated topics and the tuning overhead. Furthermore, calibrating LDA helps identify twice as many duplicates than untuned LDA when inspecting the top five past similar reports. Conclusion: No meta-heuristic and/or fitness function outperforms all the others, as advocated in prior studies. However, we can make recommendations for some combinations of meta-heuristics and fitness functions over others for practical use. Future work should focus on improving the surrogate metrics used to calibrate/tune LDA in an unsupervised fashion.","tags":["Topic Modeling","Latent Dirichlet Allocation","Search-based Software Engineering"," Meta-heuristics","Bug Reports","Hyperparameter optimization"],"title":"A Systematic Comparison of Search-Based Approaches for LDA Hyperparameter Tuning","type":"publication"},{"authors":["Annibale Panichella","Sebastiano Panichella","Gordon Fraser","Anand Ashok Sawant","Vincent Hellendoorn"],"categories":[],"content":"","date":1596549957,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596549957,"objectID":"a6329aaf5cd9c9d40de23ca3218e6e5f","permalink":"/publication/icsme2020/","publishdate":"2020-08-04T16:05:57+02:00","relpermalink":"/publication/icsme2020/","section":"publication","summary":"Test smells attempt to capture design issues in test code that reduce their maintainability. Previous work found such smells to be highly common in automatically generated test-cases, but based this result on specific static detection rules; although these are based on the original definition of “test smells”, a recent empirical study showed that developers perceive these as overly strict and non-representative of the maintainability and quality of test suites. This leads us to investigate how effective such test smell detection tools are on automatically generated test suites. In this paper, we build dataset of 2,340 test cases automatically generated by EVOSUITE for 100 Java classes. We performed a multi-stage, cross-validated manual analysis to identify six types of test smells and label their instances. We benchmark the performance of two test smell detection tools: one widely used in prior work, and one recently introduced with the express goal to match developer perceptions of test smells. Our results show that these test smell detection strategies poorly characterized the issues in automatically generated test suites; the older tool’s detection strategies, especially, misclassified over 70% of test smells, both missing real instances (false negatives) and marking many smell- free tests as smelly (false positives). We identify common patterns in these tests that can be used to improve the tools, refine and update the definition of certain test smells, and highlight as of yet uncharacterized issues. Our findings suggest the need for (i) more appropriate metrics to match development practice; and (ii) more accurate detection strategies, to be evaluated primarily in industrial contexts.","tags":["Test Case Generation","Unit Testing","Test Smells","Replication Study"],"title":"Revisiting Test Smells in Automatically Generated Tests: Limitations, Pitfalls, and Opportunities","type":"publication"},{"authors":["Devjeet Roy","Ziyi Zhang","Maggie Ma","Venera Arnaoudova","Annibale Panichella","Sebastiano Panichella","Danielle Gonzalez","Mehdi Mirakhorli"],"categories":[],"content":"","date":1596140871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596140871,"objectID":"f8c407f2ea8bfc5b4fad5f4be7b6ab39","permalink":"/publication/ase2020b/","publishdate":"2020-07-30T22:27:51+02:00","relpermalink":"/publication/ase2020b/","section":"publication","summary":"Automated test case generation tools have been successfully pro- posed to reduce the amount of human and infrastructure resources required to write and run test cases. However, recent studies demonstrate that the readability of generated tests is very limited due to (i) uninformative identifiers and (ii) lack of proper documentation. Prior studies proposed techniques to improve test readability by either generating natural language summaries or meaningful methods names. While these approaches are shown to improve test readability, they are also affected by two limitations: (1) generated summaries are often perceived as too verbose and redundant by developers, and (2) readable tests require both proper method names but also meaningful identifiers (within-method readability). In this work, we combine template based methods and Deep Learning (DL) approaches to automatically generate test case scenarios (elicited from natural language patterns of test case statements) as well as to train DL models on path-based representations of source code to generate meaningful identifier names. Our ap- proach, called DeepTC-Enhancer , recommends documentation and identifier names with the ultimate goal of enhancing readability of automatically generated test cases. An empirical evaluation with 36 external and internal developers shows that (1) DeepTC-Enhancer outperforms significantly the baseline approach for generating summaries and performs equally with the baseline approach for test case renaming, (2) the transformation proposed by DeepTC-Enhancer result in a significant increase in readability of automatically generated test cases, and (3) there is a significant difference in the feature preferences between external and internal developers.","tags":["Code Summarization","Deep Learning","Test Readability","Test Scenario","Automated Documentation"],"title":"DeepTC-Enhancer: Improving the Readability of Automatically Generated Tests","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Andy Zaidman","Arie van Deursen","A. Panichella"],"categories":[],"content":"","date":1596140866,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596140866,"objectID":"9eaa27df573f6c9ae1fa63d13347efe0","permalink":"/publication/ase2020a/","publishdate":"2020-07-30T22:27:46+02:00","relpermalink":"/publication/ase2020a/","section":"publication","summary":"Evolutionary intelligence approaches have been successfully applied to assist developers during debugging by generating a test case reproducing reported crashes. These approaches use a single fitness function called CrashFunction to guide the search process toward reproducing a target crash. Despite the reported achievements, these approaches do not always successfully reproduce some crashes due to a lack of test diversity (premature convergence). In this study, we introduce a new approach, called MO-HO, that addresses this issue via multi-objectivization. In particular, we introduce two new Helper-Objectives for crash reproduction, namely test length (to minimize) and method sequence diversity (to maximize), in addition to CrashFunction. We assessed MO-HO using five multi-objective evolutionary algorithms (NSGA-II, SPEA2, PESA-II, MOEA/D, FEMO) on 124 hard-to-reproduce crashes stemming from open-source projects. Our results indicate that SPEA2 is the best-performing multi-objective algorithm for MO-HO. We evaluated this best-performing algorithm for MO-HO against the state-of-the-art: single-objective approach (SGGA) and decomposition-based multi-objectivization approach (decomposition). Our results show that MO-HO reproduces five crashes that cannot be reproduced by the current state-of-the-art. Besides, MO-HO improves the effectiveness (+10% and +8% in reproduction ratio) and the efficiency in 34.6% and 36% of crashes (i.e., significantly lower running time) compared to SGGA and decomposition, respectively. For some crashes, the improvements are very large, being up to +93.3% for reproduction ratio and -92% for the required running time.","tags":["Crash Replication","Test Case Generation","Search-based Software Engineering","Multi-objective Optimization","Botsing"],"title":"Good Things Come In Threes: Improving Search-based Crash Reproduction With Helper Objectives","type":"publication"},{"authors":null,"categories":null,"content":"","date":1595063835,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595063835,"objectID":"2f815092abbe46f574e758db0b900248","permalink":"/talk/issta2020/","publishdate":"2020-07-18T11:17:15+02:00","relpermalink":"/talk/issta2020/","section":"talk","summary":"","tags":[],"title":"Automated Repair of Feature Interaction Failures in Automated Driving Systems","type":"talk"},{"authors":["Mitchell Olsthoorn","Arie van Deursen","Annibale Panichella"],"categories":[],"content":"","date":1594038590,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594038590,"objectID":"1aced2fe37781e98668ba6e93814e2a7","permalink":"/publication/ase2020-nier/","publishdate":"2020-07-06T14:29:50+02:00","relpermalink":"/publication/ase2020-nier/","section":"publication","summary":"Software testing is an important and time-consuming task that is often done manually. In the last decades, researchers have come up with techniques to generate input data (e.g., fuzzing) and automate the process of generating test cases (e.g., search-based testing). However, these techniques are known to have their own limitations: search-based testing does not generate highly-structured data; grammar-based fuzzing does not generate test case structures. To address these limitations, we combine these two techniques. By applying grammar-based mutations to the input data gathered by the search-based testing algorithm, it allows us to co-evolve both aspects of test case generation. We evaluate our approach by performing an empirical study on 20 Java classes from the three most popular JSON parsers across multiple search budgets. Our results show that the proposed approach on average improves branch coverage for JSON related classes by 15% (with a maximum increase of 50%) without negatively impacting other classes.","tags":["Fuzzing","Test Case Generation","Search-Based Software Engineering","Many-objective Optimization","EvoSuite"],"title":"Generating Highly-structured Input Data by Combining Search-based Testing and Grammar-based Fuzzing","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Annibale Panichella","Andy Zaidman","Arie van Deursen"],"categories":[],"content":"","date":1593951593,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594037993,"objectID":"58a66d0cc70206562c4e019f40ff3ae9","permalink":"/publication/ase2020-tool/","publishdate":"2020-07-05T14:19:53+02:00","relpermalink":"/publication/ase2020-tool/","section":"publication","summary":"Approaches for automatic crash reproduction aim to generate test cases that reproduce crashes starting from the crash stack traces. These tests help developers during their debugging practices. One of the most promising techniques in this research field leverages search-based software testing techniques for generating crash reproducing test cases. In this paper, we introduce Botsing, an open-source search-based crash reproduction framework for Java. Botsing implements state-of-the-art and novel approaches for crash reproduction. The well-documented architecture of Botsing makes it an easy-to-extend framework, and can hence be used for implementing new approaches to improve crash reproduction. We have applied Botsing to a wide range of crashes collected from open source systems. Furthermore, we conducted a qualitative assessment of the crash-reproducing test cases with our industrial partners. In both cases, Botsing could reproduce a notable amount of the given stack traces.","tags":["Search-Based Software Engineering","Crash Replication","Debugging","Botsing"],"title":"Botsing, a Search-based Crash Reproduction Framework for Java","type":"publication"},{"authors":["Pouria Derakhshanfar","Xavier Devroey","Annibale Panichella","Andy Zaidman","Arie van Deursen"],"categories":[],"content":"","date":1593881814,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593881814,"objectID":"5726de311f15b7842ef26d52416a014b","permalink":"/publication/gecco2020/","publishdate":"2020-07-04T18:56:54+02:00","relpermalink":"/publication/gecco2020/","section":"publication","summary":"Evolutionary-based crash reproduction techniques aid developers in their debugging practices by generating a test case that reproduces a crash given its stack trace. In these techniques, the search process is typically guided by a single search objective called Crash Distance. Previous studies have shown that current approaches could only reproduce a limited number of crashes due to a lack of diversity in the population during the search. In this study, we address this issue by applying Multi-Objectivization using Helper-Objectives (MO-HO) on crash reproduction. In particular, we add two helper-objectives to the Crash Distance to improve the diversity of the generated test cases and consequently enhance the guidance of the search process. We assessed MO-HO against the single-objective crash reproduction. Our results show that MO-HO can reproduce two additional crashes that were not previously reproducible by the single-objective approach.","tags":["Crash Replication","Test Case Generation","Software Testing","Search-based Software Engineering"],"title":"Crash Reproduction Using Helper Objectives","type":"publication"},{"authors":["A. Panichella","J. Campos","G. Fraser"],"categories":null,"content":"","date":1587139000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587139000,"objectID":"8256a3b27d4ce54e626a9102cbf76d46","permalink":"/publication/sbst2020/","publishdate":"2020-04-17T17:56:40+02:00","relpermalink":"/publication/sbst2020/","section":"publication","summary":"EvoSuite is a search-based tool that automatically generates executable unit tests for Java code (JUnit tests). This paper summarizes the results and experiences of EvoSuite’s participation at the eighth unit testing competition at SBST 2020, where EvoSuite achieved the highest overall score (406.14 points) for the seventh time in eight editions of the competition.","tags":["Test Case Generation","EvoSuite"],"title":"EvoSuite at the SBST 2020 Tool Competition","type":"publication"},{"authors":["Raja Ben Abdessalem","Annibale Panichella","Shiva Nejati","Lionel Briand","Thomas Stifter"],"categories":null,"content":"","date":1587137574,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587137574,"objectID":"87d6049d74ae533120a7502409ca9af9","permalink":"/publication/issta2020/","publishdate":"2020-04-17T17:32:54+02:00","relpermalink":"/publication/issta2020/","section":"publication","summary":"The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed; for supervised ML applications, oracle information is indeed available in the form of dataset “ground truth”, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system integrity. While syntactic issues may be automatically verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for SE strategies that especially target and assess the oracle.","tags":["Self-driving Cars","Program Repair","Search-based Software Engineering"],"title":"Automated Repair of Feature Interaction Failures in Automated Driving Systems","type":"publication"},{"authors":["Carolin E. Brandt","Annibale Panichella","Andy Zaidman","Moritz Beller"],"categories":null,"content":"","date":1583251717,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583251717,"objectID":"970c6ecf48da3dd6ad1292fcfad15b6a","permalink":"/publication/msrdata2019/","publishdate":"2020-03-03T17:08:37+01:00","relpermalink":"/publication/msrdata2019/","section":"publication","summary":"Build logs are textual by-products that a software build process creates, often as part of its Continuous Integration (CI) pipeline. Build logs are a paramount source of information for developers when debugging into and understanding a build failure. Recently, attempts to partly automate this time-consuming, purely manual activity have come up, such as rule- or information-retrieval-based techniques. We believe that having a common data set to compare different build log analysis techniques will advance the research area. It will ultimately increase our understanding of CI build failures. In this paper, we present LogChunks, a collection of 797 annotated Travis CI build logs from 80 GitHub repositories in 29 programming languages. For each build log, LogChunks contains a manually labeled log part (chunk) describing why the build failed. We externally validated the data set with the developers who caused the original build failure. The width and depth of the LogChunks data set are intended to make it the default benchmark for automated build log analysis techniques","tags":["Log Analysis","Dataset"],"title":"LogChunks: A Data Set for Build Log Analysis","type":"publication"},{"authors":["Cynthia C. S. Liem","Annibale Panichella"],"categories":null,"content":"Abstract: The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed; for supervised ML applications, oracle information is indeed available in the form of dataset \u0026ldquo;ground truth\u0026rdquo;, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system integrity. While syntactic issues may be automatically verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for SE strategies that especially target and assess the oracle.\n","date":1583248815,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583248815,"objectID":"2e85d797b28bafb67c7d817fce5bff50","permalink":"/publication/raise2020/","publishdate":"2020-03-03T16:20:15+01:00","relpermalink":"/publication/raise2020/","section":"publication","summary":"The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed. For supervised ML applications, oracle information is indeed available in the form of dataset ‘ground truth’, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system's integrity. While syntactic issues may automatically be verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for software engineering strategies that especially target and assess the oracle.","tags":["Deep Learning","Test Oracle","Artificial Intelligence"],"title":"Oracle Issues in Machine Learning and Where to Find Them","type":"publication"},{"authors":null,"categories":null,"content":"","date":1572254235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572254235,"objectID":"4b0612ef59bd79f89de0f63555417d9c","permalink":"/talk/ipa2019/","publishdate":"2019-10-28T11:17:15+02:00","relpermalink":"/talk/ipa2019/","section":"talk","summary":"","tags":["test case generation","software testing","search-based software engineering"],"title":"Automated Test Generation for Unit Testing Beyond","type":"talk"},{"authors":["Giovanni Grano","Christoph Laaber","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"Abstract: Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects. In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases. This study shows that performance-aware test case generation requires solving two main challenges: providing a good approximation of resource usage with minimal overhead and\navoiding detrimental effects on both final coverage and fault detection effectiveness. To tackle these challenges, we conceived a set of performance proxies -inspired by previous work on performance testing- that provide a reasonable estimation of the test execution costs (i.e., runtime and memory usage). Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing. Our empirical study -involving 110 non-trivial Java classes- reveals that our adaptive approach generates test suite with statistically significant improvements in runtime (-25%) and heap memory consumption (-15%) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness. Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.\n","date":1570607493,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570607493,"objectID":"c47926aa7591d5dcd34cab937390d6f5","permalink":"/publication/ieee-tse2019/","publishdate":"2019-10-09T09:51:33+02:00","relpermalink":"/publication/ieee-tse2019/","section":"publication","summary":"Abstract: Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects.","tags":["Test Case Generation","Evolutionary Testing","Performance Testing","Search-based Software Engineering"],"title":"Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1569921435,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569921435,"objectID":"16fd7abf4972671f80ca8e508c794c1b","permalink":"/talk/cow2019/","publishdate":"2019-10-01T11:17:15+02:00","relpermalink":"/talk/cow2019/","section":"talk","summary":"","tags":["self-driving cars","software testing","feature interactions"],"title":"Testing Autonomous Cars for Feature Interaction Failures using Evolutionary Intelligence","type":"talk"},{"authors":["Dimitri Michel Stallenberg","Annibale Panichella"],"categories":null,"content":"","date":1561538501,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561538501,"objectID":"efa028a3ccd165d576f491b24ee28681","permalink":"/publication/esec-fse2019/","publishdate":"2019-06-26T10:41:41+02:00","relpermalink":"/publication/esec-fse2019/","section":"publication","summary":"","tags":["Security Testing","Meta-heuristics","XML-injection"],"title":"JCOMIX: A Search-Based Tool to Detect XML Injection Vulnerabilities in Web Applications","type":"publication"},{"authors":null,"categories":[],"content":"","date":1561537772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561537772,"objectID":"7ed1d0f9afe59297a980e62e87f9e3b4","permalink":"/tools/catcher/","publishdate":"2019-06-26T10:29:32+02:00","relpermalink":"/tools/catcher/","section":"tools","summary":"Tool that combines static exception propagation and search-based software testing to automatically detect (and generate test cases) for API misuses in Java client programs.","tags":["Search-based Software Engineering","Static Analysis","API Misuse Detection"],"title":"Catcher","type":"tools"},{"authors":null,"categories":[],"content":"Towards Integration-Level Test Case Generation Using Call Site Information\n","date":1561537772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561537772,"objectID":"8a0229bec8c025b51010bd29e805c459","permalink":"/tools/cling/","publishdate":"2019-06-26T10:29:32+02:00","relpermalink":"/tools/cling/","section":"tools","summary":"Test Case Generation for Class Integration Testing","tags":["Search-based Software Engineering","Test Case Generation","integration Testing"],"title":"Cling","type":"tools"},{"authors":null,"categories":[],"content":"A Systematic Comparison of Search Algorithms for Topic Modelling - A Study on Duplicate\rBug Report Identification\nAuthor Annibale Panichella\nVenue SSBSE 2019\nAbstract Latent Dirichlet Allocation (LDA) has been used to support\rmany software engineering tasks. Previous studies showed that default\rsettings lead to sub-optimal topic modeling with a dramatic impact\ron the performance of such approaches in terms of precision and\rrecall. For this reason, researchers used search algorithms (e.g., genetic\ralgorithms) to automatically configure topic models in an unsupervised\rfashion. While previous work showed the ability of individual search algorithms\rin finding near-optimal configurations, it is not clear to what\rextent the choice of the meta-heuristic matters for SE tasks. In this paper,\rwe present a systematic comparison of five different meta-heuristics\rto configure LDA in the context of duplicate bug reports identification.\rThe results show that (1) no master algorithm outperforms the others\rfor all software projects, (2) random search and PSO are the least effective\rmeta-heuristics. Finally, the running time strongly depends on the\rcomputational complexity of LDA while the internal complexity of the\rsearch algorithms plays a negligible role.\nGetting started The source code is available in GitHub at the link: https://github.com/apanichella/Search-Based-LDA\n","date":1561537772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561537772,"objectID":"bbe1685c369a0cb81eb9577b28a51924","permalink":"/tools/ssbse-lda/","publishdate":"2019-06-26T10:29:32+02:00","relpermalink":"/tools/ssbse-lda/","section":"tools","summary":"R Scripts to configure LDA using meta-heuristics","tags":["Search-based Software Engineering","Meta-heuristics","Topic Model","Unsupervised Learning"],"title":"Search-Based-LDA","type":"tools"},{"authors":["Maria Kechagia","Xavier Devroey","Annibale Panichella","Georgios Gousios","Arie van Deursen"],"categories":null,"content":" Abstract : Application Programming Interfaces (APIs) typically come with (implicit) usage constraints. The violations of these constraints (API misuses) can lead to software crashes. Even though there are several tools that can detect API misuses, most of them suffer from a very high rate of false positives. We introduce Catcher, a novel API misuse detection approach that combines static exception propagation analysis with automatic search-based test case generation to effectively and efficiently pinpoint crash-prone API misuses in client applications. We validate Catcher against 21 Java applications, targeting misuses of the Java platform\u0026rsquo;s API. Our results indicate that Catcher is able to generate test cases that uncover 243 (unique) API misuses that result in crashes. Our empirical evaluation shows that Catcher can detect a large number of misuses (77 cases) that would remain undetected by the traditional coverage-based test case generator EvoSuite. Additionally, Catcher is on average eight times faster than EvoSuite in generating test cases for the identified misuses. Finally, we find that the majority of the exceptions triggered by Catcher are unexpected to developers i.e., not only unhandled in the source code but also not listed in the documentation of the client applications.\n","date":1556734971,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556734971,"objectID":"2fe58cf372a8bf8a56eef68645e340ef","permalink":"/publication/issta2019/","publishdate":"2019-05-01T20:22:51+02:00","relpermalink":"/publication/issta2019/","section":"publication","summary":"Abstract : Application Programming Interfaces (APIs) typically come with (implicit) usage constraints. The violations of these constraints (API misuses) can lead to software crashes. Even though there are several tools that can detect API misuses, most of them suffer from a very high rate of false positives.","tags":["Search-based Software Engineering","Software Testing","Static Analysis"],"title":"Effective and Efficient API Misuse Detection via Exception Propagation and Search-based Testing","type":"publication"},{"authors":["Annibale Panichella"],"categories":null,"content":"Abstract Latent Dirichlet Allocation (LDA) has been used to support many software engineering tasks. Previous studies showed that default settings lead to sub-optimal topic modeling with a dramatic impact on the performance of such approaches in terms of precision and recall. For this reason, researchers used search algorithms (e.g., genetic algorithms) to automatically configure topic models in an unsupervised fashion. While previous work showed the ability of individual search algorithms in finding near-optimal configurations, it is not clear to what extent the choice of the meta-heuristic matters for SE tasks. In this paper, we present a systematic comparison of five different meta-heuristics to configure LDA in the context of duplicate bug reports identification. The results show that (1) no master algorithm outperforms the others for all software projects, (2) random search and PSO are the least effective meta-heuristics. Finally, the running time strongly depends on the computational complexity of LDA while the internal complexity of the search algorithms plays a negligible role.\n","date":1556572583,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556572583,"objectID":"efdf8aa40e6215036334850f1908e81f","permalink":"/publication/ssbse2019/","publishdate":"2019-04-29T23:16:23+02:00","relpermalink":"/publication/ssbse2019/","section":"publication","summary":"Abstract Latent Dirichlet Allocation (LDA) has been used to support many software engineering tasks. Previous studies showed that default settings lead to sub-optimal topic modeling with a dramatic impact on the performance of such approaches in terms of precision and recall.","tags":["Topic Model","Search-based Software Engineering","Hyperparameter Tuning"],"title":"A Systematic Comparison of Search Algorithms for Topic Modelling - A Study on Duplicate Bug Report Identification","type":"publication"},{"authors":null,"categories":null,"content":"Title An Adaptive Evolutionary Algorithm based on Non-Euclidean Geometry for Many-objective Optimization\nAuthor Annibale Panichella\nVenue GECCO 2019\nAbstract In the last decade, several evolutionary algorithms have been proposed in the literature for solving multi- and many-objective optimization problems. The performance of such algorithms depends on their capability to produce a well-diversified front (diversity) that is as closer to the Pareto optimal front as possible (proximity). Diversity and proximity strongly depend on the geometry of the Pareto front, i.e., whether it forms a Euclidean, spherical or hyperbolic hypersurface. However, existing multi- and many-objective evolutionary algorithms show poor versatility on different geometries. To address this issue, we propose a novel evolutionary algorithm that: (1) estimates the geometry of the generated front using a fast procedure with O(MxN) computational complexity (M is the number of objectives and N is the population size); (2) adapts the diversity and proximity metrics accordingly. Therefore, to form the population for the next generation, solutions are selected based on their contribution to the diversity and proximity of the non-dominated front with regards to the estimated geometry. Computational experiments show that the proposed algorithm outperforms state-of-the-art multi and many-objective evolutionary algorithms on benchmark test problems with different geometries and number of objectives (M=3,5, and 10).\nGetting started The source code of AGE-MOEA can be downloaded: here\nAGE-MOEA is implemented as a module (algorithm) to include in the platform PlatEMO. Download the zip file (see link above) and extract its content in the folder Algorithms of PlatEMO.\n","date":1554714534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554714534,"objectID":"72f92f0d4efad050fdcc7a49f23ee247","permalink":"/tools/age-moea/","publishdate":"2019-04-08T11:08:54+02:00","relpermalink":"/tools/age-moea/","section":"tools","summary":"Implementation of AGE-MOEA in Matlab","tags":["Many-objective Optimization","Evolutionary Computation","Matlab","Benchmark"],"title":"AGE-MOEA","type":"tools"},{"authors":null,"categories":null,"content":"","date":1554714534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554714534,"objectID":"2e050a4e88a108da954f088b4501d62f","permalink":"/project/cosmos/","publishdate":"2019-04-08T11:08:54+02:00","relpermalink":"/project/cosmos/","section":"project","summary":"Emerging Cyber-Physical Systems (CPS)—from robotics, transportation, to medical devices—play a crucial role in the quality of life of European citizens and the future of the European economy. Increasing automation to such an extent, however, gives rise to many challenges, at the crux of which lies the hardware and software symbiosis. COSMOS proposes to overcome the strain on developing and evolving high-quality, dependable CPS by employing two key technologies: DevOps and Artificial Intelligence (AI). These technologies offer the potential to address CPS development, verification, and evolution. ","tags":[],"title":"DevOps for Complex Cyber-physical Systems","type":"project"},{"authors":null,"categories":null,"content":"","date":1554714534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554714534,"objectID":"cfe54b9016245ca0673f0ac774371eda","permalink":"/project/stamp/","publishdate":"2019-04-08T11:08:54+02:00","relpermalink":"/project/stamp/","section":"project","summary":"STAMP stands for Software Testing AMPlification. Leveraging advanced research in automatic test generation, STAMP aims at pushing automation in DevOps one step further through innovative methods of test amplification. STAMP will reuse existing assets (test cases, API descriptions, dependency models), in order to generate more test cases and test configurations each time the application is updated. ","tags":[],"title":"Software Testing Amplification for the DevOps Team","type":"project"},{"authors":null,"categories":null,"content":"","date":1554714529,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554714529,"objectID":"7d85601b1af7ad47d5b53ce3a61d615d","permalink":"/project/ripple/","publishdate":"2019-04-08T11:08:49+02:00","relpermalink":"/project/ripple/","section":"project","summary":"UBRI is a partnership between Ripple and top universities around the world to support academic research, technical development and innovation in blockchain, cryptocurrency and , digital payments. Ripple is providing both financial and technical resources to university partners and collaborates with faculty and students on research and technical projects.","tags":[],"title":"University Blockchain Research Initiative ","type":"project"},{"authors":["Annibale Panichella"],"categories":null,"content":"","date":1554713130,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554713130,"objectID":"b6d1f8b3fe683ac0780842d7dbdf7584","permalink":"/publication/gecco2019/","publishdate":"2019-04-08T10:45:30+02:00","relpermalink":"/publication/gecco2019/","section":"publication","summary":"In the last decade, several evolutionary algorithms have been proposed in the literature for solving multi- and many-objective optimization problems. The performance of such algorithms depends on their capability to produce a well-diversified front (diversity) that is as closer to the Pareto optimal front as possible (proximity). Diversity and proximity strongly depend on the geometry of the Pareto front, i.e., whether it forms a Euclidean, spherical or hyperbolic hypersurface. However, existing multi- and many-objective evolutionary algorithms show poor versatility on different geometries. To address this issue, we propose a novel evolutionary algorithm that: (1) estimates the geometry of the generated front using a fast procedure with O(M × N) computational complexity (M is the number of objectives and N is the population size); (2) adapts the diversity and proximity metrics accordingly. Therefore, to form the population for the next generation, solutions are selected based on their contribution to the diversity and proximity of the non-dominated front with regards to the estimated geometry. Computational experiments show that the proposed algorithm outperforms state-of-the-art multi and many-objective evolutionary algorithms on benchmark test problems with different geometries and number of objectives (M=3,5, and 10).","tags":["Many-objective Optimization","Numerical Problems","Evolutionary Computation"],"title":"An Adaptive Evolutionary Algorithm based on Non-Euclidean Geometry for Many-objective Optimization","type":"publication"},{"authors":["José Campos","Annibale Panichella","Gordon Fraser"],"categories":null,"content":"","date":1554712910,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554712910,"objectID":"dfe2b1370f3ca9a86e68eed505e81311","permalink":"/publication/sbst2019b/","publishdate":"2019-04-08T10:41:50+02:00","relpermalink":"/publication/sbst2019b/","section":"publication","summary":"","tags":["Test Case Generation","EvoSuite"],"title":"EvoSuite at the SBST 2019 Tool Competition","type":"publication"},{"authors":["Annibale Panichella"],"categories":null,"content":"","date":1554712743,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554712743,"objectID":"320f9ff67498056114556147a9a6884e","permalink":"/publication/sbst2019a/","publishdate":"2019-04-08T10:39:03+02:00","relpermalink":"/publication/sbst2019a/","section":"publication","summary":"","tags":["Test Case Generation"],"title":"Beyond Unit-Testing in Search-based Test Case Generation: Challenges and Opportunities","type":"publication"},{"authors":["Sadeeq Jan","Annibale Panichella","Andrea Arcuri","Lionel Briand"],"categories":null,"content":"","date":1554711079,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554711079,"objectID":"73907a1174c90a03d99e8252001f74b1","permalink":"/publication/emse2019/","publishdate":"2019-04-08T10:11:19+02:00","relpermalink":"/publication/emse2019/","section":"publication","summary":"","tags":["Security Testing","XML-injection","Test Case Generation","Many-objective Optimization"],"title":"Search-based Multi-Vulnerability Testing of XML Injections in Web Applications","type":"publication"},{"authors":null,"categories":null,"content":"","date":1549012635,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549012635,"objectID":"136c988c787faab1e91f041f4c9d54da","permalink":"/talk/sen2019/","publishdate":"2019-02-01T11:17:15+02:00","relpermalink":"/talk/sen2019/","section":"talk","summary":"","tags":[],"title":"Speeding-up Software Testing using Computational intelligence","type":"talk"},{"authors":["Dario Di Nucci","Annibale Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1536400262,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536400262,"objectID":"39e4cea3da0a7fda712645e31fd0069f","permalink":"/publication/ieee-tse2018f/","publishdate":"2018-09-08T11:51:02+02:00","relpermalink":"/publication/ieee-tse2018f/","section":"publication","summary":"","tags":["Test Case Prioritization","Regression Testing","Hypervolume","Meta-heuristics"],"title":"A Test Case Prioritization Genetic Algorithm guided by the Hypervolume Indicator","type":"publication"},{"authors":["Annibale Panichella","Fitsum M. Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1534570793,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534570793,"objectID":"2744582b83c3971ea8f42c388a8fa7d9","permalink":"/publication/infsof2018b/","publishdate":"2018-08-18T07:39:53+02:00","relpermalink":"/publication/infsof2018b/","section":"publication","summary":"","tags":["Test Case Generation","Many-objective optimization","EvoSuite"],"title":"A Large Scale Empirical Comparison of State-of-the-art Search-based Test Case Generators","type":"publication"},{"authors":["Fabio Palomba","Dario Di Nucci","Anniable Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1534180440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534180440,"objectID":"e42732a5efd57aad1dfd78180d575d90","permalink":"/publication/infsoft2018a/","publishdate":"2018-08-13T19:14:00+02:00","relpermalink":"/publication/infsoft2018a/","section":"publication","summary":"","tags":["Code Smell","Energy Consumption","Mobile App"],"title":"On the Impact of Code Smells on the Energy Consumption of Mobile Applications","type":"publication"},{"authors":["Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1534179336,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534179336,"objectID":"604e8b3bb9980795251968610a9785df","permalink":"/publication/ieee-tse2018e/","publishdate":"2018-08-13T18:55:36+02:00","relpermalink":"/publication/ieee-tse2018e/","section":"publication","summary":"","tags":["Crash Replication","Debugging","Meta-heuristics"],"title":"Search-Based Crash Reproduction and Its Impact on Debugging","type":"publication"},{"authors":["Annibale Panichella","Fitsum M. Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1532038074,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532038074,"objectID":"ba2dd19cace7d239e0351b069665dcab","permalink":"/publication/ssbse2018b/","publishdate":"2018-07-20T00:07:54+02:00","relpermalink":"/publication/ssbse2018b/","section":"publication","summary":"","tags":["Test Case Generation","Search-based Software Engineering","Many-objective Optimization","EvoSuite"],"title":"Incremental Control Dependency Frontier Exploration for Many-Criteria Test Case Generation","type":"publication"},{"authors":["Mozhan Soltani","Pouria Derakhshanfar","Annibale Panichella","Xavier Devroey","Andy Zaidman","Arie van Deursen"],"categories":null,"content":"","date":1532037994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037994,"objectID":"68d33bcc1e1df9d31b6f222f7c7e8b90","permalink":"/publication/ssbse2018a/","publishdate":"2018-07-20T00:06:34+02:00","relpermalink":"/publication/ssbse2018a/","section":"publication","summary":"","tags":["Crash Replication","Multi-objective Optimization","Debugging"],"title":"Single-objective versus Multi-Objectivized Optimization for Evolutionary Crash Reproduction","type":"publication"},{"authors":["Salma Messaoudi","Annibale Panichella","Domenico Bianculli","Lionel Briand","Raimondas Sasnauskas"],"categories":null,"content":"","date":1532037913,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037913,"objectID":"87a5a29ac12380df54f3c5a7f2f89c6b","permalink":"/publication/icpc2018/","publishdate":"2018-07-20T00:05:13+02:00","relpermalink":"/publication/icpc2018/","section":"publication","summary":"","tags":["Log Analysis","Meta-heuristics","Search-based Software Engineering"],"title":"A Search-based Approach for Accurate Identification of Log Message Formats","type":"publication"},{"authors":["Jeroen Castelein","Mauricio Aniche","Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1532037844,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037844,"objectID":"453e29161b35199dc94a43e84bee9b11","permalink":"/publication/icse2018/","publishdate":"2018-07-20T00:04:04+02:00","relpermalink":"/publication/icse2018/","section":"publication","summary":"","tags":["Test Case Generation","SQL","Software Testing"],"title":"Search-Based Test Data Generation for SQL Queries","type":"publication"},{"authors":["Qianqian Zhu","Annibale Panichella","Andy Zaidman"],"categories":null,"content":"","date":1532037782,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037782,"objectID":"f75b458b91a7599d8de3ff41cb1a50b5","permalink":"/publication/icst2018/","publishdate":"2018-07-20T00:03:02+02:00","relpermalink":"/publication/icst2018/","section":"publication","summary":"","tags":["Mutation Testing","Concept Analysis"],"title":"An Investigation of Compression Techniques to Speed up Mutation Testing","type":"publication"},{"authors":["R. Abdessalem","A. Panichella","S. Nejati","L. Briand","T. Stifter"],"categories":null,"content":"","date":1532037716,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037716,"objectID":"c96bde9303e09d8bf37013044c55f26d","permalink":"/publication/ase2018/","publishdate":"2018-07-20T00:01:56+02:00","relpermalink":"/publication/ase2018/","section":"publication","summary":"","tags":["Self-Driving Cars","Test Case Generation","Search-based Software Engineering"],"title":"Testing Autonomous Cars for Feature Interaction Failures using Many-Objective Search","type":"publication"},{"authors":["Urko R. Molina","Fitsum M. Kifetew","Annibale Panichella"],"categories":null,"content":"","date":1532037674,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037674,"objectID":"5d1c113f2c70125a81c6bae62de5d6e6","permalink":"/publication/sbst2018/","publishdate":"2018-07-20T00:01:14+02:00","relpermalink":"/publication/sbst2018/","section":"publication","summary":"","tags":["Test Case Generation","Competition"],"title":"Java Unit Testing Tool Competition - Sixth Round","type":"publication"},{"authors":["Fabio Palomba","Annibale Panichella","Andy Zaidman","Rocco Oliveto","Andrea De Lucia"],"categories":null,"content":"","date":1531214749,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214749,"objectID":"e16ae3d544d8c8707851ac079e75b191","permalink":"/publication/ieee-tse2018d/","publishdate":"2018-07-10T11:25:49+02:00","relpermalink":"/publication/ieee-tse2018d/","section":"publication","summary":"","tags":["Code Smell","Software Quality"],"title":"The Scent of a Smell: An Extensive Comparison between Textual and Structural Smells","type":"publication"},{"authors":["Moritz Beller","Georgios Gousios","Annibale Panichella","Sebastian Proksch","Sven Amann","Andy Zaidman"],"categories":null,"content":"","date":1531214686,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214686,"objectID":"71a21199e02b5d57f1a6febffc38594a","permalink":"/publication/ieee-tse2018c/","publishdate":"2018-07-10T11:24:46+02:00","relpermalink":"/publication/ieee-tse2018c/","section":"publication","summary":"","tags":["Software Testing","Empirical Software Engineering"],"title":"Developer Testing in The IDE: Patterns, Beliefs, And Behavior","type":"publication"},{"authors":["Annibale Panichella","Fitsum M. Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1531214614,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214614,"objectID":"0a8267a7ff26a9e44a9f357939443e57","permalink":"/publication/ieee-tse2018b/","publishdate":"2018-07-10T11:23:34+02:00","relpermalink":"/publication/ieee-tse2018b/","section":"publication","summary":"","tags":["Test Case Generation","Evolutionary Testing","Search-based Software Engineering","Many-objective Optimization"],"title":"Automated Test Case Generation as a Many-Objective Optimisation Problem with Dynamic Selection of the Targets","type":"publication"},{"authors":["Sadeeq. Jan","Annibale Panichella","Andrea Arcuri","Lionel Briand"],"categories":null,"content":"","date":1531214505,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531214505,"objectID":"cf1be60b13298cb2b4f01a36d781c085","permalink":"/publication/ieee-tse2018a/","publishdate":"2018-07-10T11:21:45+02:00","relpermalink":"/publication/ieee-tse2018a/","section":"publication","summary":"","tags":["Security Testing","XML-injection","Meta-heuristics"],"title":"Automatic Generation of Tests to Exploit XML Injection Vulnerabilities in Web Applications","type":"publication"},{"authors":["Dennis Appelt","Cu D. Nguyen","Annibale Panichella","Lionel Briand"],"categories":null,"content":"","date":1531213882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531213882,"objectID":"1006313693093d2fd8ce9da5112cad03","permalink":"/publication/ieee-tr2018/","publishdate":"2018-07-10T11:11:22+02:00","relpermalink":"/publication/ieee-tr2018/","section":"publication","summary":"","tags":["Machine Learning","Security Testing","Meta-heuristics","Security Testing"],"title":"A Machine Learning- Driven Evolutionary Approach for Testing Web Application Firewalls","type":"publication"},{"authors":["Q. Zhu","A. Panichella","A. Zaidman"],"categories":null,"content":"","date":1531213882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531213882,"objectID":"c1cfb73626c50df12bab9c05742fc13a","permalink":"/publication/stvr2018/","publishdate":"2018-07-10T11:11:22+02:00","relpermalink":"/publication/stvr2018/","section":"publication","summary":"","tags":["Mutation Testing"],"title":"A Systematic Literature Review of How Mutation Testing Supports Quality Assurance Processes","type":"publication"},{"authors":["Dario Di Nucci","Fabio Palomba","Annibale Panichella","Andy Zaidman","Andrea De Lucia,"],"categories":null,"content":"","date":1502647828,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647828,"objectID":"9a0a6ad5d54947a55eff35217a8333ba","permalink":"/publication/saner2017b/","publishdate":"2017-08-13T20:10:28+02:00","relpermalink":"/publication/saner2017b/","section":"publication","summary":"","tags":["Code Smell","Mobile App"],"title":"Lightweight Detection of Android-specific Code Smells: the aDoctor Project","type":"publication"},{"authors":["Dario Di Nucci","Fabio Palomba","Andrea Prota","Annibale Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1502647712,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647712,"objectID":"b5d0bf5e3e64a17fbbdd1398756bdc19","permalink":"/publication/saner2017a/","publishdate":"2017-08-13T20:08:32+02:00","relpermalink":"/publication/saner2017a/","section":"publication","summary":"","tags":["Energy Consumption","Profiling","Mobile App"],"title":"Software-Based Energy Profiling of Android Apps: Simple, Efficient and Reliable","type":"publication"},{"authors":["Qianqian Zhu","Annibale Panichella","Andy Zaidman"],"categories":null,"content":"","date":1502647608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647608,"objectID":"ee0d42b67d8129c7c79b3815a6b6a1b2","permalink":"/publication/icstw2017/","publishdate":"2017-08-13T20:06:48+02:00","relpermalink":"/publication/icstw2017/","section":"publication","summary":"","tags":[],"title":"Speeding-Up Mutation Testing via Data Compression and State Infection","type":"publication"},{"authors":["Annibale Panichella","Urko Molina"],"categories":null,"content":"","date":1502647507,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502647507,"objectID":"eb76c93ac2234bc483195d49f475cc1e","permalink":"/publication/sbst2017/","publishdate":"2017-08-13T20:05:07+02:00","relpermalink":"/publication/sbst2017/","section":"publication","summary":"","tags":["Test Case Generation","Competition"],"title":"Java Unit Testing Tool Competition - Fifth Round","type":"publication"},{"authors":["Dario Di Nucci","Fabio Palomba","Annibale Panichella","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1502645831,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502645831,"objectID":"debdd3062b3b9c52f6d6ccd151481871","permalink":"/publication/icse2017-tool/","publishdate":"2017-08-13T19:37:11+02:00","relpermalink":"/publication/icse2017-tool/","section":"publication","summary":"","tags":["Energy Consumption","Profiling","Mobile Apps"],"title":"PETrA: a Software-Based Tool for Estimating the Energy Profile of Android Applications","type":"publication"},{"authors":["Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1502645657,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502645657,"objectID":"ffb7a46400e38a154b5bf15f032a223b","permalink":"/publication/icse2017/","publishdate":"2017-08-13T19:34:17+02:00","relpermalink":"/publication/icse2017/","section":"publication","summary":"","tags":["Crash Replication","Debugging","Test Case Generation"],"title":"Guided Genetic Algorithm for Automated Crash Reproduction","type":"publication"},{"authors":["Dennis Appelt","Annibale Panichella","Lionel Briand"],"categories":null,"content":"","date":1502645293,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502645293,"objectID":"4685ca945045f96fb91b0ee7e902b07b","permalink":"/publication/issre2018/","publishdate":"2017-08-13T19:28:13+02:00","relpermalink":"/publication/issre2018/","section":"publication","summary":"","tags":[],"title":"Automatically Repairing Web Application Firewalls Based on Successful SQL Injection Attacks","type":"publication"},{"authors":["Annibale Panichella","Fitsum Kifetew","Paolo Tonella"],"categories":null,"content":"","date":1499968982,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499968982,"objectID":"63b8e3f8a57ab1749bf9dcae3a37841d","permalink":"/publication/ssbse2017/","publishdate":"2017-07-13T20:03:02+02:00","relpermalink":"/publication/ssbse2017/","section":"publication","summary":"","tags":["Test Case Generation","Search-based Software Engineering","EvoSuite"],"title":"LIPS vs MOSA: a Replicated Empirical Study on Automated Test Case Generation","type":"publication"},{"authors":["Annibale Panichella","Bogdan Dit","Rocco Oliveto","Massimiliano Di Penta","Denys Poshyvanyk","Andrea De Lucia"],"categories":null,"content":"","date":1471500046,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471500046,"objectID":"ec33f4ab84674c1973e52c2c61f72885","permalink":"/publication/saner2016/","publishdate":"2016-08-18T08:00:46+02:00","relpermalink":"/publication/saner2016/","section":"publication","summary":"","tags":["Topic Model","Traceability Recovery","Debugging","Meta-heuristics"],"title":"Parameterizing and Assembling IR-based Solutions for Software Engineering Tasks using Genetic Algorithms","type":"publication"},{"authors":["Fabio Palomba","Dario Di Nucci","Annibale Panichella","Rocco Oliveto","Andrea De Lucia"],"categories":null,"content":"","date":1471499942,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499942,"objectID":"e44a2924dc15f9b7f4fe8346ee3bba7c","permalink":"/publication/sbst2016b/","publishdate":"2016-08-18T07:59:02+02:00","relpermalink":"/publication/sbst2016b/","section":"publication","summary":"","tags":["Test Smell"],"title":"On the Diffusion of Test Smells in Automatically Generated Test Code: An Empirical Study","type":"publication"},{"authors":["Mozhan Soltani","Annibale Panichella","Arie van Deursen"],"categories":null,"content":"","date":1471499779,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499779,"objectID":"70533af01f178ca387c7055984e613ca","permalink":"/publication/sbst2016a/","publishdate":"2016-08-18T07:56:19+02:00","relpermalink":"/publication/sbst2016a/","section":"publication","summary":"","tags":["Crash Replication","Evolutionary Testing","Test Case Generation"],"title":"Evolutionary Testing for Crash Reproduction","type":"publication"},{"authors":["M. Beller","I. Levaja","A. Panichella","G. Gousios","A. Zaidman"],"categories":null,"content":"","date":1471499655,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499655,"objectID":"e1693b47828696e413dd9da43a7d6d04","permalink":"/publication/serip2016/","publishdate":"2016-08-18T07:54:15+02:00","relpermalink":"/publication/serip2016/","section":"publication","summary":"","tags":["Software Testing","Empirical Software Engineering"],"title":"How to Catch 'Em All: WatchDog, a Family of IDE Plug-Ins to Assess Testing","type":"publication"},{"authors":["Fabio Palomba","Annibale Panichella","Rocco Oliveto","Andy Zaidman","Andrea De Lucia"],"categories":null,"content":"","date":1471499570,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499570,"objectID":"ac4bd56debc24bb1b70783a7e676e103","permalink":"/publication/icpc2016/","publishdate":"2016-08-18T07:52:50+02:00","relpermalink":"/publication/icpc2016/","section":"publication","summary":"","tags":["Code Smell","Information Retrieval","Software Quality"],"title":"A Textual-based Technique for Smell Detection","type":"publication"},{"authors":["C. Vassallo","F. Zampetti","D. Romano","M. Beller","A. Panichella","M. Di Penta","A. Zaidman"],"categories":null,"content":"","date":1471499470,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499470,"objectID":"f292bdc578ff461fa055aba488585ec8","permalink":"/publication/icsme2016/","publishdate":"2016-08-18T07:51:10+02:00","relpermalink":"/publication/icsme2016/","section":"publication","summary":"","tags":["Empirical Software Engineering"],"title":"Continuous Delivery Practices in a Large Financial Organization","type":"publication"},{"authors":["Annibale Panichella","Carol V. Alexandru","Sebastiano Panichella","Alberto Bacchelli","Harald Gall"],"categories":null,"content":"","date":1471499254,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499254,"objectID":"bcbbefb00a399e754f88f796ade8c056","permalink":"/publication/gecco2016/","publishdate":"2016-08-18T07:47:34+02:00","relpermalink":"/publication/gecco2016/","section":"publication","summary":"","tags":["Defect Prediction","Machine Learning","Meta-heuristics"],"title":"A Search-based Training Algorithm for Cost-aware Prediction","type":"publication"},{"authors":["Fabio Palomba","Annibale Panichella","Andy Zaidman","Rocco Oliveto","Andrea De Lucia"],"categories":null,"content":"","date":1471499136,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499136,"objectID":"ecc556be4c6384fba659108bf4b8c4d0","permalink":"/publication/issta2016/","publishdate":"2016-08-18T07:45:36+02:00","relpermalink":"/publication/issta2016/","section":"publication","summary":"","tags":["Test Case Generation","Test Smell","EvoSuite"],"title":"Automatic Test Case Generation: What If Test Code Quality Matters?","type":"publication"},{"authors":["Sebastiano Panichella","Annibale Panichella","Moritz Beller","Andy Zaidman","Harald C. Gall"],"categories":null,"content":"","date":1471499006,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471499006,"objectID":"1ea54cbb7420ac807bc9695196dd7e96","permalink":"/publication/icse2016/","publishdate":"2016-08-18T07:43:26+02:00","relpermalink":"/publication/icse2016/","section":"publication","summary":"","tags":["Software Testing","Debugging","Empirical Software Engineering"],"title":"The impact of test case summaries on bug fixing performance: An empirical investigation","type":"publication"},{"authors":["G. Canfora","A. De Lucia","M. Di Penta","R. Oliveto","A. Panichella","S. Panichella"],"categories":null,"content":"","date":1437342641,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437342641,"objectID":"8a037fb6dff481ee5695a14d2aacaa6e","permalink":"/publication/stvr2015/","publishdate":"2015-07-19T23:50:41+02:00","relpermalink":"/publication/stvr2015/","section":"publication","summary":"","tags":["Defect Prediction","Multi-objective Optimization","Machine Learning"],"title":"Defect Prediction as a Multi-Objective Optimization Problem","type":"publication"},{"authors":["Annibale Panichella","Rocco Oliveto","Massimiliano Di Penta","Andrea De Lucia"],"categories":null,"content":"Abstract: A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.\n","date":1437342396,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437342396,"objectID":"1c0deac416dc345f999b5fdf953acd9e","permalink":"/publication/tse2015/","publishdate":"2015-07-19T23:46:36+02:00","relpermalink":"/publication/tse2015/","section":"publication","summary":"Abstract: A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem.","tags":["Regression Testing","Search-based Software Engineering","Test Case Selection"],"title":"Improving Multi-Objective Search Based Test Suite Optimization through Diversity Injection","type":"publication"},{"authors":["Andrea De Lucia","Massimiliano Di Penta","Rocco Oliveto","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1405806774,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405806774,"objectID":"cc270ace894d74074b08767f42ddf9d7","permalink":"/publication/emse2014/","publishdate":"2014-07-19T23:52:54+02:00","relpermalink":"/publication/emse2014/","section":"publication","summary":"","tags":["Information Retrieval","Topic Model","Empirical Software Engineering"],"title":"Labeling Source Code with Information Retrieval Methods: An Empirical Study.","type":"publication"},{"authors":["Giovanni Capobianco","Andrea De Lucia","Rocco Oliveto","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1342734949,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1342734949,"objectID":"c77e6b4ed38050ad83b9577eb3041f5b","permalink":"/publication/jse2012/","publishdate":"2012-07-19T23:55:49+02:00","relpermalink":"/publication/jse2012/","section":"publication","summary":"","tags":["Information Retrieval","Traceability Recovery"],"title":"Improving IR-based traceability recovery via noun-based indexing of software artifacts","type":"publication"},{"authors":["Andrea De Lucia","Massimiliano Di Penta","Rocco Oliveto","Annibale Panichella","Sebastiano Panichella"],"categories":null,"content":"","date":1342734859,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1342734859,"objectID":"23c663d9beb777bc3a2265e251f7cf52","permalink":"/publication/infsoft/","publishdate":"2012-07-19T23:54:19+02:00","relpermalink":"/publication/infsoft/","section":"publication","summary":"","tags":["Information Retrieval","Traceability Recovery","Smoothing Filter"],"title":"Applying a Smoothing Filter to Improve IR-based Traceability Recovery Processes: An Empirical Investigation.","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"322dbaccf72a6d71f827fdb2866be935","permalink":"/teaching/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/teaching/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]
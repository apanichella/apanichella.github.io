<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Annibale Panichella on Annibale Panichella</title>
    <link>https://apanichella.github.io/</link>
    <description>Recent content in Annibale Panichella on Annibale Panichella</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>EvoSuite at the SBST 2020 Tool Competition</title>
      <link>https://apanichella.github.io/publication/sbst2020/</link>
      <pubDate>Fri, 17 Apr 2020 17:56:40 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/sbst2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automated Repair of Feature Interaction Failures in Automated Driving Systems</title>
      <link>https://apanichella.github.io/publication/issta2020/</link>
      <pubDate>Fri, 17 Apr 2020 17:32:54 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/issta2020/</guid>
      <description>&lt;p&gt;Abstract:
The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed; for supervised ML applications, oracle information is indeed available in the form of dataset “ground truth”, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system integrity. While syntactic issues may be automatically verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for SE strategies that especially target and assess the oracle.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LogChunks: A Data Set for Build Log Analysis</title>
      <link>https://apanichella.github.io/publication/msrdata2019/</link>
      <pubDate>Tue, 03 Mar 2020 17:08:37 +0100</pubDate>
      
      <guid>https://apanichella.github.io/publication/msrdata2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Oracle Issues in Machine Learning and Where to Find Them</title>
      <link>https://apanichella.github.io/publication/raise2020/</link>
      <pubDate>Tue, 03 Mar 2020 16:20:15 +0100</pubDate>
      
      <guid>https://apanichella.github.io/publication/raise2020/</guid>
      <description>&lt;p&gt;Abstract:
The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed; for supervised ML applications, oracle information is indeed available in the form of dataset &amp;ldquo;ground truth&amp;rdquo;, that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system integrity. While syntactic issues may be automatically verified and corrected, the higher-level issues traditionally need human judgment and manual analysis.
In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for SE strategies that especially target and assess the oracle.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation</title>
      <link>https://apanichella.github.io/publication/ieee-tse2019/</link>
      <pubDate>Wed, 09 Oct 2019 09:51:33 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/ieee-tse2019/</guid>
      <description>&lt;p&gt;Abstract: Automated test case generation is an effective technique to yield high-coverage test suites.
While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects.
In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases.
This study shows that performance-aware test case generation requires solving two main challenges:
providing a good approximation of resource usage with minimal overhead and&lt;br /&gt;
avoiding detrimental effects on both final coverage and fault detection effectiveness.
To tackle these challenges, we conceived a set of performance proxies -inspired by previous work on performance testing- that provide a reasonable estimation of the test execution costs (i.e., runtime and memory usage).
Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing.
Our empirical study -involving 110 non-trivial Java classes- reveals
that our adaptive approach generates test suite with statistically significant improvements in runtime (-25\%) and heap memory consumption (-15\%) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness.
Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>JCOMIX: A Search-Based Tool to Detect XML Injection Vulnerabilities in Web Applications</title>
      <link>https://apanichella.github.io/publication/esec-fse2019/</link>
      <pubDate>Wed, 26 Jun 2019 10:41:41 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/esec-fse2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Search-Based-LDA</title>
      <link>https://apanichella.github.io/tools/ssbse-lda/</link>
      <pubDate>Wed, 26 Jun 2019 10:29:32 +0200</pubDate>
      
      <guid>https://apanichella.github.io/tools/ssbse-lda/</guid>
      <description>

&lt;p&gt;A Systematic Comparison of Search Algorithms for Topic Modelling - A Study on Duplicate
Bug Report Identification&lt;/p&gt;

&lt;h3 id=&#34;author&#34;&gt;Author&lt;/h3&gt;

&lt;p&gt;Annibale Panichella&lt;/p&gt;

&lt;h3 id=&#34;venue&#34;&gt;Venue&lt;/h3&gt;

&lt;p&gt;SSBSE 2019&lt;/p&gt;

&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;

&lt;p&gt;Latent Dirichlet Allocation (LDA) has been used to support
many software engineering tasks. Previous studies showed that default
settings lead to sub-optimal topic modeling with a dramatic impact
on the performance of such approaches in terms of precision and
recall. For this reason, researchers used search algorithms (e.g., genetic
algorithms) to automatically configure topic models in an unsupervised
fashion. While previous work showed the ability of individual search algorithms
in finding near-optimal configurations, it is not clear to what
extent the choice of the meta-heuristic matters for SE tasks. In this paper,
we present a systematic comparison of five different meta-heuristics
to configure LDA in the context of duplicate bug reports identification.
The results show that (1) no master algorithm outperforms the others
for all software projects, (2) random search and PSO are the least effective
meta-heuristics. Finally, the running time strongly depends on the
computational complexity of LDA while the internal complexity of the
search algorithms plays a negligible role.&lt;/p&gt;

&lt;h3 id=&#34;getting-started&#34;&gt;Getting started&lt;/h3&gt;

&lt;p&gt;The source code is available in GitHub at the link: &lt;a href=&#34;https://github.com/apanichella/Search-Based-LDA&#34; target=&#34;_blank&#34;&gt;https://github.com/apanichella/Search-Based-LDA&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Effective and Efficient API Misuse Detection via Exception Propagation and Search-based Testing</title>
      <link>https://apanichella.github.io/publication/issta2019/</link>
      <pubDate>Wed, 01 May 2019 20:22:51 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/issta2019/</guid>
      <description>&lt;p&gt;&lt;b&gt; Abstract &lt;/b&gt;: Application Programming Interfaces (APIs)
typically come with (implicit) usage constraints.
The violations of these constraints (API misuses)
can lead to software crashes.
Even though there are several tools that
can detect API misuses,
most of them suffer from a very high rate of false positives.
We introduce Catcher, a novel API misuse detection approach
that combines static exception propagation analysis with automatic search-based test case
generation to effectively and efficiently pinpoint crash-prone API misuses
in client applications.
We validate Catcher against 21 Java applications,
targeting misuses of the Java platform&amp;rsquo;s API.
Our results indicate that Catcher is able to generate
test cases that uncover 243 (unique) API misuses that result in
crashes.
Our empirical evaluation shows that Catcher can detect a large number of misuses (77 cases)
that would remain undetected by the traditional coverage-based test case generator EvoSuite.
Additionally, Catcher is on average eight times faster than EvoSuite
in generating test cases for the identified misuses.
Finally, we find that the majority of the exceptions triggered by Catcher
are unexpected to developers i.e., not only unhandled in the source code but also not listed in the documentation of the client applications.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Systematic Comparison of Search Algorithms for Topic Modelling - A Study on Duplicate Bug Report Identification</title>
      <link>https://apanichella.github.io/publication/ssbse2019/</link>
      <pubDate>Mon, 29 Apr 2019 23:16:23 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/ssbse2019/</guid>
      <description>

&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Latent Dirichlet Allocation (LDA) has been used to support many software engineering tasks. Previous studies showed that default settings lead to sub-optimal topic modeling with a dramatic impact on the performance of such approaches in terms of precision and recall. For this reason, researchers used search algorithms (e.g., genetic algorithms) to automatically configure topic models in an unsupervised fashion. While previous work showed the ability of individual search algorithms in finding near-optimal configurations, it is not clear to what extent the choice of the meta-heuristic matters for SE tasks. In this paper, we present a systematic comparison of five different meta-heuristics to configure LDA in the context of duplicate bug reports identification. The results show that (1) no master algorithm outperforms the others for all software projects, (2) random search and PSO are the least effective meta-heuristics. Finally, the running time strongly depends on the computational complexity of LDA while the internal complexity of the search algorithms plays a negligible role.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AGE-MOEA</title>
      <link>https://apanichella.github.io/tools/age-moea/</link>
      <pubDate>Mon, 08 Apr 2019 11:08:54 +0200</pubDate>
      
      <guid>https://apanichella.github.io/tools/age-moea/</guid>
      <description>

&lt;h3 id=&#34;title&#34;&gt;Title&lt;/h3&gt;

&lt;p&gt;An Adaptive Evolutionary Algorithm based on Non-Euclidean Geometry for Many-objective Optimization&lt;/p&gt;

&lt;h3 id=&#34;author&#34;&gt;Author&lt;/h3&gt;

&lt;p&gt;Annibale Panichella&lt;/p&gt;

&lt;h3 id=&#34;venue&#34;&gt;Venue&lt;/h3&gt;

&lt;p&gt;GECCO 2019&lt;/p&gt;

&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;

&lt;p&gt;In the last decade, several evolutionary algorithms have been proposed in the literature for solving multi- and many-objective optimization problems. The performance of such algorithms depends on their capability to produce a well-diversified front (diversity) that is as closer to the Pareto optimal front as possible (proximity). Diversity and proximity strongly depend on the geometry of the Pareto front, i.e., whether it forms a Euclidean, spherical or hyperbolic hypersurface.  However, existing multi- and many-objective evolutionary algorithms show poor versatility on different geometries. To address this issue, we propose a novel evolutionary algorithm that: (1) estimates the geometry of the generated front using a fast procedure with O(MxN) computational complexity (M is the number of objectives and N is the population size); (2) adapts the diversity and proximity metrics accordingly. Therefore, to form the population for the next generation, solutions are selected based on their contribution to the diversity and proximity of the non-dominated front with regards to the estimated geometry. Computational experiments show that the proposed algorithm outperforms state-of-the-art multi and many-objective evolutionary algorithms on benchmark test problems with different geometries and number of objectives (M=3,5, and 10).&lt;/p&gt;

&lt;h3 id=&#34;getting-started&#34;&gt;Getting started&lt;/h3&gt;

&lt;p&gt;The source code of AGE-MOEA can be downloaded: &lt;a href=&#34;https://github.com/apanichella/PlatEMO&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AGE-MOEA is implemented as a module (algorithm) to include in the platform &lt;a href=&#34;https://github.com/BIMK/PlatEMO&#34;&gt;PlatEMO&lt;/a&gt;.
Download the zip file (see link above) and extract its content in the folder &lt;code&gt;Algorithms&lt;/code&gt; of &lt;code&gt;PlatEMO&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Software Testing Amplification for the DevOps Team</title>
      <link>https://apanichella.github.io/project/stamp/</link>
      <pubDate>Mon, 08 Apr 2019 11:08:54 +0200</pubDate>
      
      <guid>https://apanichella.github.io/project/stamp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>University Blockchain Research Initiative </title>
      <link>https://apanichella.github.io/project/ripple/</link>
      <pubDate>Mon, 08 Apr 2019 11:08:49 +0200</pubDate>
      
      <guid>https://apanichella.github.io/project/ripple/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Adaptive Evolutionary Algorithm based on Non-Euclidean Geometry for Many-objective Optimization</title>
      <link>https://apanichella.github.io/publication/gecco2019/</link>
      <pubDate>Mon, 08 Apr 2019 10:45:30 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/gecco2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EvoSuite at the SBST 2019 Tool Competition</title>
      <link>https://apanichella.github.io/publication/sbst2019b/</link>
      <pubDate>Mon, 08 Apr 2019 10:41:50 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/sbst2019b/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond Unit-Testing in Search-based Test Case Generation: Challenges and Opportunities</title>
      <link>https://apanichella.github.io/publication/sbst2019a/</link>
      <pubDate>Mon, 08 Apr 2019 10:39:03 +0200</pubDate>
      
      <guid>https://apanichella.github.io/publication/sbst2019a/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
